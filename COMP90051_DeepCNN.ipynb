{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13286972,"sourceType":"datasetVersion","datasetId":8420823}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:16.200284Z","iopub.execute_input":"2025-10-08T00:32:16.200908Z","iopub.status.idle":"2025-10-08T00:32:16.983818Z","shell.execute_reply.started":"2025-10-08T00:32:16.200877Z","shell.execute_reply":"2025-10-08T00:32:16.983001Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/shoe-images/train_B.npz\n/kaggle/input/shoe-images/test.npz\n/kaggle/input/shoe-images/train_A.npz\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, random, numpy as np\nimport torch\nfrom torchvision import models\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:16.985330Z","iopub.execute_input":"2025-10-08T00:32:16.985709Z","iopub.status.idle":"2025-10-08T00:32:16.990212Z","shell.execute_reply.started":"2025-10-08T00:32:16.985689Z","shell.execute_reply":"2025-10-08T00:32:16.989374Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:16.991008Z","iopub.execute_input":"2025-10-08T00:32:16.991233Z","iopub.status.idle":"2025-10-08T00:32:17.006870Z","shell.execute_reply.started":"2025-10-08T00:32:16.991216Z","shell.execute_reply":"2025-10-08T00:32:17.006136Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"data_dir = \"/kaggle/input/shoe-images\"\ndata = np.load(os.path.join(data_dir, \"train_B.npz\"))  # or train_A.npz\nX, y = data[\"X\"], data[\"y\"]\nprint(\"Loaded:\", X.shape, y.shape)\n\n# ---------- encode string labels to ints ----------\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)            # e.g. Boot→0, Sandal→1, Shoe→2\nprint(\"Label mapping:\", dict(zip(encoder.classes_,\n                                 range(len(encoder.classes_)))))\n\n# ---------- normalise images ----------\nX = X.astype(\"float32\") / 255.0\n\n# ---------- reshape for PyTorch (N,C,H,W) ----------\nX = np.transpose(X, (0,3,1,2))\ny = y.astype(\"int64\")\nnum_classes = len(np.unique(y))\nprint(\"Final tensors:\", X.shape, \"Classes:\", num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:17.008489Z","iopub.execute_input":"2025-10-08T00:32:17.008690Z","iopub.status.idle":"2025-10-08T00:32:37.489615Z","shell.execute_reply.started":"2025-10-08T00:32:17.008674Z","shell.execute_reply":"2025-10-08T00:32:37.488893Z"}},"outputs":[{"name":"stdout","text":"Loaded: (12000, 224, 224, 3) (12000,)\nLabel mapping: {'Boot': 0, 'Sandal': 1, 'Shoe': 2}\nFinal tensors: (12000, 3, 224, 224) Classes: 3\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def make_folds(n, k=10, seed=42, y=None):\n    \"\"\"\n    Create stratified k-fold splits that preserve class distribution.\n    \n    Parameters:\n    - n: Total number of samples\n    - k: Number of folds (default=10)\n    - seed: Random seed for reproducibility (default=42)\n    - y: Labels for stratification (required)\n    \n    Returns:\n    - List of k arrays containing indices for each fold\n    \"\"\"\n    np.random.seed(seed)\n    \n    unique_classes = np.unique(y)\n    folds = [[] for _ in range(k)]\n    \n    # For each class, split its samples across k folds\n    for cls in unique_classes:\n        cls_indices = np.where(y == cls)[0]\n        np.random.shuffle(cls_indices)\n        cls_splits = np.array_split(cls_indices, k)\n        \n        # Add class samples to each fold\n        for fold_idx, split in enumerate(cls_splits):\n            folds[fold_idx].extend(split)\n    \n    # Shuffle within each fold and convert to numpy arrays\n    for i in range(k):\n        np.random.shuffle(folds[i])\n        folds[i] = np.array(folds[i])\n    \n    return folds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.490352Z","iopub.execute_input":"2025-10-08T00:32:37.490614Z","iopub.status.idle":"2025-10-08T00:32:37.496237Z","shell.execute_reply.started":"2025-10-08T00:32:37.490594Z","shell.execute_reply":"2025-10-08T00:32:37.495559Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def confusion_matrix_manual(y_true, y_pred, labels):\n    n = len(labels)\n    label_to_idx = {lab: i for i, lab in enumerate(labels)}\n    cm = np.zeros((n, n), dtype=int)\n    for yt, yp in zip(y_true, y_pred):\n        i = label_to_idx[yt]\n        j = label_to_idx[yp]\n        cm[i, j] += 1\n    return cm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.497284Z","iopub.execute_input":"2025-10-08T00:32:37.497516Z","iopub.status.idle":"2025-10-08T00:32:37.513412Z","shell.execute_reply.started":"2025-10-08T00:32:37.497491Z","shell.execute_reply":"2025-10-08T00:32:37.512663Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def calc_metrics(cm):\n    TP = np.diag(cm)\n    FP = cm.sum(0) - TP\n    FN = cm.sum(1) - TP\n    precision = np.mean(TP / (TP + FP + 1e-9))\n    recall    = np.mean(TP / (TP + FN + 1e-9))\n    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n    acc = TP.sum() / cm.sum()\n    return acc, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.514198Z","iopub.execute_input":"2025-10-08T00:32:37.514381Z","iopub.status.idle":"2025-10-08T00:32:37.534028Z","shell.execute_reply.started":"2025-10-08T00:32:37.514367Z","shell.execute_reply":"2025-10-08T00:32:37.533394Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_one_fold(X_train, y_train, X_val, y_val, model_builder,\n                   lr=1e-3, epochs=5, batch=64, device=\"cpu\"):\n    \"\"\"Train one fold and return model + predictions on validation set.\"\"\"\n    \n    train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n    val_ds   = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n    train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n    val_dl   = DataLoader(val_ds, batch_size=batch, shuffle=False)\n\n    # note: difference here — build model dynamically\n    model = model_builder().to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    opt = optim.Adam(model.parameters(), lr=lr)\n\n    for ep in range(epochs):\n        model.train()\n        total_loss = 0.0\n        for xb, yb in train_dl:\n            xb, yb = xb.to(device), yb.to(device)\n            out = model(xb)\n            loss = loss_fn(out, yb)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            total_loss += loss.item()\n        avg_loss = total_loss / len(train_dl)\n        print(f\"  Epoch {ep+1}/{epochs}, Train loss={avg_loss:.4f}\")\n\n    # ----- validation predictions -----\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for xb, _ in val_dl:\n            xb = xb.to(device)\n            probs = torch.softmax(model(xb), 1)\n            preds.append(torch.argmax(probs, 1).cpu().numpy())\n    preds = np.concatenate(preds)\n    return model, preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.534780Z","iopub.execute_input":"2025-10-08T00:32:37.535032Z","iopub.status.idle":"2025-10-08T00:32:37.548647Z","shell.execute_reply.started":"2025-10-08T00:32:37.535011Z","shell.execute_reply":"2025-10-08T00:32:37.547949Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate_model_nested_cv(\n    X, y, model_builder,\n    candidate_lr=[1e-3, 3e-4, 1e-4],\n    k_outer=10, k_inner=3, epochs=5,\n    device=\"cpu\"\n):\n    \"\"\"Generic nested cross‑validation for any model.\"\"\"\n\n    folds = make_folds(len(X), k_outer, seed=42, y=y)\n    metrics_all = []\n\n    for i in range(k_outer):\n        print(f\"\\n=== Outer Fold {i+1}/{k_outer} ===\")\n\n        test_idx = folds[i]\n        train_idx = np.concatenate([folds[j] for j in range(k_outer) if j != i])\n        X_train, y_train = X[train_idx], y[train_idx]\n        X_test,  y_test  = X[test_idx],  y[test_idx]\n\n        # ---- inner loop: tuning learning rate ----\n        inner_folds = make_folds(len(X_train), k_inner, seed=42, y=y_train)\n        mean_accs = []\n\n        for lr in candidate_lr:\n            inner_scores = []\n            for j in range(k_inner):\n                val_idx = inner_folds[j]\n                tr_idx  = np.concatenate([inner_folds[m] for m in range(k_inner) if m != j])\n\n                _, y_pred_val = train_one_fold(\n                    X_train[tr_idx], y_train[tr_idx],\n                    X_train[val_idx], y_train[val_idx],\n                    model_builder=model_builder,\n                    lr=lr, epochs=2, device=device\n                )\n\n                cm = confusion_matrix_manual(y_train[val_idx], y_pred_val, labels=np.unique(y))\n                acc, prec, rec, f1 = calc_metrics(cm)\n                inner_scores.append(acc)\n\n            mean_accs.append(np.mean(inner_scores))\n\n        best_lr = candidate_lr[int(np.argmax(mean_accs))]\n        print(f\"Best LR = {best_lr:.0e}\")\n\n        # ---- outer test fold ----\n        model, y_pred = train_one_fold(\n            X_train, y_train, X_test, y_test,\n            model_builder=model_builder,\n            lr=best_lr, epochs=epochs, device=device\n        )\n\n        cm = confusion_matrix_manual(y_test, y_pred, labels=np.unique(y))\n        acc, prec, rec, f1 = calc_metrics(cm)\n        metrics_all.append([acc, prec, rec, f1])\n\n        print(f\"Fold {i+1}: Acc={acc:.3f}, P={prec:.3f}, R={rec:.3f}, F1={f1:.3f}\")\n\n    # ---- summary ----\n    metrics_all = np.array(metrics_all)\n    mean, std = metrics_all.mean(0), metrics_all.std(0)\n\n    print(\"\\n=== Nested CV Results ===\")\n    print(f\"Accuracy : {mean[0]:.3f} ± {std[0]:.3f}\")\n    print(f\"Precision: {mean[1]:.3f} ± {std[1]:.3f}\")\n    print(f\"Recall   : {mean[2]:.3f} ± {std[2]:.3f}\")\n    print(f\"F1-score : {mean[3]:.3f} ± {std[3]:.3f}\")\n\n    return mean, std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.549289Z","iopub.execute_input":"2025-10-08T00:32:37.549450Z","iopub.status.idle":"2025-10-08T00:32:37.568245Z","shell.execute_reply.started":"2025-10-08T00:32:37.549436Z","shell.execute_reply":"2025-10-08T00:32:37.567565Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class DeepCNN(nn.Module):\n    def __init__(self, n_classes):\n        super().__init__()\n        # Feature extractor\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),  # 32 filters\n            nn.ReLU(),\n            nn.MaxPool2d(2),                 # Downsample\n\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.MaxPool2d(2)\n        )\n\n        self.flatten_dim = None\n        self.classifier = None\n        self.n_classes = n_classes\n\n    def _get_flatten_dim(self, x):\n        with torch.no_grad():\n            f = self.features(x)\n            return f.view(f.size(0), -1).shape[1]\n\n    def forward(self, x):\n        if self.classifier is None:\n            flat_dim = self._get_flatten_dim(x)\n            self.classifier = nn.Sequential(\n                nn.Flatten(),\n                nn.Linear(flat_dim, 128), nn.ReLU(),\n                nn.Dropout(0.4),\n                nn.Linear(128, self.n_classes)\n            ).to(x.device)\n        out = self.features(x)\n        out = self.classifier(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.570043Z","iopub.execute_input":"2025-10-08T00:32:37.570233Z","iopub.status.idle":"2025-10-08T00:32:37.586434Z","shell.execute_reply.started":"2025-10-08T00:32:37.570218Z","shell.execute_reply":"2025-10-08T00:32:37.585851Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# --- DeepCNN ---\nprint(\"\\n### Evaluating DeepCNN ###\")\ndeep_mean, deep_std = evaluate_model_nested_cv(\n    X, y,\n    model_builder=lambda: DeepCNN(num_classes),\n    candidate_lr=[1e-3, 3e-4, 1e-4],\n    k_outer=10,\n    k_inner=3,\n    epochs=3,\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T00:32:37.587094Z","iopub.execute_input":"2025-10-08T00:32:37.587338Z"}},"outputs":[{"name":"stdout","text":"\n### Evaluating DeepCNN ###\n\n=== Outer Fold 1/10 ===\n  Epoch 1/2, Train loss=0.8032\n  Epoch 2/2, Train loss=0.6589\n  Epoch 1/2, Train loss=0.8462\n  Epoch 2/2, Train loss=0.6724\n  Epoch 1/2, Train loss=0.8590\n  Epoch 2/2, Train loss=0.6707\n  Epoch 1/2, Train loss=0.9411\n  Epoch 2/2, Train loss=0.7641\n  Epoch 1/2, Train loss=0.9211\n  Epoch 2/2, Train loss=0.7310\n  Epoch 1/2, Train loss=0.9102\n  Epoch 2/2, Train loss=0.7200\n  Epoch 1/2, Train loss=1.0020\n  Epoch 2/2, Train loss=0.8750\n  Epoch 1/2, Train loss=1.0085\n  Epoch 2/2, Train loss=0.8685\n  Epoch 1/2, Train loss=1.0003\n  Epoch 2/2, Train loss=0.8759\nBest LR = 1e-03\n  Epoch 1/3, Train loss=0.7936\n  Epoch 2/3, Train loss=0.6336\n  Epoch 3/3, Train loss=0.5724\nFold 1: Acc=0.816, P=0.822, R=0.816, F1=0.819\n\n=== Outer Fold 2/10 ===\n  Epoch 1/2, Train loss=0.8975\n  Epoch 2/2, Train loss=0.7105\n  Epoch 1/2, Train loss=0.8501\n  Epoch 2/2, Train loss=0.6593\n  Epoch 1/2, Train loss=0.8332\n","output_type":"stream"}],"execution_count":null}]}