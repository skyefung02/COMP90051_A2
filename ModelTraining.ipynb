{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5ade774-0530-450b-ae15-be0a811f1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os, cv2\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea06e77-1ed7-4da0-8ab8-81bb741baa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainA: (12000, 224, 224, 3), trainB: (12000, 224, 224, 3), test: (3000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./augmented_data\"\n",
    "\n",
    "def load_npz_dataset(filename):\n",
    "    path = os.path.join(data_dir, filename)\n",
    "    data = np.load(path)\n",
    "    return data[\"X\"], data[\"y\"]\n",
    "\n",
    "X_train_A, y_train_A = load_npz_dataset(\"train_A.npz\")   # original clean\n",
    "X_train_B, y_train_B = load_npz_dataset(\"train_B.npz\")   # augmented / degraded\n",
    "X_test, y_test       = load_npz_dataset(\"test.npz\")\n",
    "\n",
    "print(f\"trainA: {X_train_A.shape}, trainB: {X_train_B.shape}, test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378c808-c254-4dbc-a6c7-2977632dc96a",
   "metadata": {},
   "source": [
    "### Manual K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a70fec7-9bc5-4806-a260-76149f079586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds(n_samples, k=10, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    folds = np.array_split(idx, k)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af49a0-09ee-4553-b4eb-560efd2fe4e2",
   "metadata": {},
   "source": [
    "### Computing Metrics Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85deb797-38f2-4001-811d-18b7975edfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(cm):\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    precision = np.mean(TP / (TP + FP + 1e-9))\n",
    "    recall = np.mean(TP / (TP + FN + 1e-9))\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    acc = TP.sum() / cm.sum()\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9effc673-b298-4449-b1fa-48814ca63027",
   "metadata": {},
   "source": [
    "### Inner CV for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8145d50f-216d-4a3b-831f-0cd544d3205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cv_tuning(X, y, candidate_C, k_inner=3):\n",
    "    \"\"\"Return the C value that gives best mean accuracy in inner CV.\"\"\"\n",
    "    folds = make_folds(len(X), k_inner)\n",
    "    avg_acc = []\n",
    "    for C in candidate_C:\n",
    "        accs = []\n",
    "        for i in range(k_inner):\n",
    "            val_idx = folds[i]\n",
    "            train_idx = np.concatenate([folds[j] for j in range(k_inner) if j != i])\n",
    "            model = SVC(kernel=\"linear\", C=C)\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            accs.append(model.score(X[val_idx], y[val_idx]))\n",
    "        avg_acc.append(np.mean(accs))\n",
    "    best_C = candidate_C[int(np.argmax(avg_acc))]\n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a029be-d121-4e58-965d-5a427e076316",
   "metadata": {},
   "source": [
    "### Outer CV for Model Evaluation (10-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa938971-066b-4e4f-bc68-c3cfada90f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm_nested_cv_pca(X, y,\n",
    "                               candidate_C=[0.1,1,10],\n",
    "                               candidate_PCs=[50,100,200],\n",
    "                               k_outer=10, k_inner=3):\n",
    "    folds = make_folds(len(X), k_outer)\n",
    "    metrics_all = []\n",
    "    for i in range(k_outer):\n",
    "        test_idx = folds[i]\n",
    "        train_idx = np.concatenate([folds[j] for j in range(k_outer) if j!=i])\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # --- scale ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test  = scaler.transform(X_test)\n",
    "\n",
    "        # --- inner loop: tune C and PCs using 3‑fold CV ---\n",
    "        best_score, bestC, bestPC = -np.inf, None, None\n",
    "        inner_folds = make_folds(len(X_train), k_inner)\n",
    "        for C in candidate_C:\n",
    "            for n_pc in candidate_PCs:\n",
    "                scores = []\n",
    "                for j in range(k_inner):\n",
    "                    val_idx = inner_folds[j]\n",
    "                    tr_idx = np.concatenate([inner_folds[m] for m in range(k_inner) if m!=j])\n",
    "                    X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n",
    "                    y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n",
    "                    pca = PCA(n_components=min(n_pc, X_tr.shape[1]), random_state=42)\n",
    "                    X_tr_pca = pca.fit_transform(X_tr)\n",
    "                    X_val_pca = pca.transform(X_val)\n",
    "                    model = SVC(kernel=\"linear\", C=C)\n",
    "                    model.fit(X_tr_pca, y_tr)\n",
    "                    scores.append(model.score(X_val_pca, y_val))\n",
    "                mean_sc = np.mean(scores)\n",
    "                if mean_sc > best_score:\n",
    "                    best_score, bestC, bestPC = mean_sc, C, n_pc\n",
    "\n",
    "        print(f\"Fold {i+1}: Best C = {bestC}, Best PCs = {bestPC}\")\n",
    "\n",
    "        # --- Train with best C and PCA on full train fold ---\n",
    "        pca_final = PCA(n_components=min(bestPC, X_train.shape[1]), random_state=42)\n",
    "        X_train_pca = pca_final.fit_transform(X_train)\n",
    "        X_test_pca  = pca_final.transform(X_test)\n",
    "\n",
    "        model = SVC(kernel=\"linear\", C=bestC)\n",
    "        model.fit(X_train_pca, y_train)\n",
    "        y_pred = model.predict(X_test_pca)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "        acc, prec, rec, f1 = calc_metrics(cm)\n",
    "        metrics_all.append([acc,prec,rec,f1])\n",
    "\n",
    "        print(f\"Fold {i+1}: Acc={acc:.3f} P={prec:.3f} R={rec:.3f} F1={f1:.3f}\")\n",
    "\n",
    "    metrics_all = np.array(metrics_all)\n",
    "    mean, std = metrics_all.mean(0), metrics_all.std(0)\n",
    "    print(\"\\nSVM With PCA Results\")\n",
    "    print(f\"Accuracy   : {mean[0]:.3f} ± {std[0]:.3f}\")\n",
    "    print(f\"Precision  : {mean[1]:.3f} ± {std[1]:.3f}\")\n",
    "    print(f\"Recall    : {mean[2]:.3f} ± {std[2]:.3f}\")\n",
    "    print(f\"F1‑Score  : {mean[3]:.3f} ± {std[3]:.3f}\")\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3601b7-134f-47f6-86b8-d8796756bb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40619909-4ec8-4053-ae00-cef4f0c751c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a6475-5422-4de4-b298-bb96a13b2e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36cd425c-16a8-4963-88cb-0021e6aaa654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_features(img, bins=(16,16,16)):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv],[0,1,2],None,bins,[0,180,0,256,0,256])\n",
    "    hist = cv2.normalize(hist,hist).flatten()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9faea6d-718c-43c6-b486-ff8745d8217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texture_features(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag, _ = cv2.cartToPolar(gx, gy)\n",
    "    edge_density = np.mean(cv2.Canny(gray,50,150)>0)\n",
    "    return [np.mean(mag), np.std(mag), edge_density]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac12e305-5ea3-4f27-a394-eb15bd34bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shape_features(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray,50,150)\n",
    "    contours,_ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        c = max(contours,key=cv2.contourArea)\n",
    "        area = cv2.contourArea(c)\n",
    "        peri = cv2.arcLength(c,True)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect_ratio = w/float(h) if h>0 else 0\n",
    "        return [area,peri,aspect_ratio,w,h]\n",
    "    return [0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7140808a-3a28-4ed5-b1ab-22746a4af7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    color = extract_color_features(img)\n",
    "    texture = extract_texture_features(img)\n",
    "    shape = extract_shape_features(img)\n",
    "    return np.hstack([color,texture,shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e48badb0-d7d7-4e9d-a2e1-2127000a6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract_features(images):\n",
    "    print(\"Extracting hand‑crafted features… \")\n",
    "    feats = [extract_features(img) for img in images]\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd7ead-84eb-42fd-9f04-67def0fbf5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ed13a-3f73-4ea3-abd7-4389f040300e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb52083-845f-49bc-a405-1810368a4624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b334b9-5547-4a15-abb2-674c7c08ef8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096e00b6-1202-4781-a185-205574171b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting hand‑crafted features… \n",
      "Extracting hand‑crafted features… \n",
      "Extracting hand‑crafted features… \n",
      "Train A features: (12000, 4104)\n",
      "Train B features: (12000, 4104)\n",
      "Test features: (3000, 4104)\n"
     ]
    }
   ],
   "source": [
    "X_trainA_feats = batch_extract_features(X_train_A)\n",
    "X_trainB_feats = batch_extract_features(X_train_B)\n",
    "X_test_feats   = batch_extract_features(X_test)\n",
    "\n",
    "print(\"Train A features:\", X_trainA_feats.shape)\n",
    "print(\"Train B features:\", X_trainB_feats.shape)\n",
    "print(\"Test features:\", X_test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ab5d6da-627d-4286-827a-9424b85936bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Best C = 0.1\n",
      "Fold 1: Acc=0.732  P=0.732  R=0.731  F1=0.732\n",
      "Fold 2: Best C = 0.1\n",
      "Fold 2: Acc=0.726  P=0.724  R=0.724  F1=0.724\n",
      "Fold 3: Best C = 0.1\n",
      "Fold 3: Acc=0.731  P=0.729  R=0.733  F1=0.731\n",
      "Fold 4: Best C = 0.1\n",
      "Fold 4: Acc=0.748  P=0.746  R=0.748  F1=0.747\n",
      "Fold 5: Best C = 0.1\n",
      "Fold 5: Acc=0.702  P=0.700  R=0.704  F1=0.702\n",
      "Fold 6: Best C = 0.1\n",
      "Fold 6: Acc=0.727  P=0.726  R=0.729  F1=0.727\n",
      "Fold 7: Best C = 0.1\n",
      "Fold 7: Acc=0.732  P=0.730  R=0.731  F1=0.730\n",
      "Fold 8: Best C = 0.1\n",
      "Fold 8: Acc=0.735  P=0.732  R=0.732  F1=0.732\n",
      "Fold 9: Best C = 0.1\n",
      "Fold 9: Acc=0.742  P=0.739  R=0.738  F1=0.739\n",
      "Fold 10: Best C = 0.1\n",
      "Fold 10: Acc=0.769  P=0.770  R=0.771  F1=0.770\n",
      "\n",
      "Final Results\n",
      "Accuracy: 0.734 ± 0.016\n",
      "Precision: 0.733 ± 0.017\n",
      "Recall: 0.734 ± 0.016\n",
      "F1‑score: 0.733 ± 0.016\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m scalerA \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m      2\u001b[0m X_trainA_scaled \u001b[38;5;241m=\u001b[39m scalerA\u001b[38;5;241m.\u001b[39mfit_transform(X_trainA_feats)\n\u001b[0;32m----> 3\u001b[0m meanA, stdA \u001b[38;5;241m=\u001b[39m evaluate_svm_nested_cv(X_trainA_scaled, y_train_A)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# augmented / degraded dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m scalerB \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "scalerA = StandardScaler()\n",
    "X_trainA_scaled = scalerA.fit_transform(X_trainA_feats)\n",
    "meanA, stdA = evaluate_svm_nested_cv(X_trainA_scaled, y_train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b38ac-569b-477f-8e5b-2c09efbe9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented / degraded dataset\n",
    "scalerB = StandardScaler()\n",
    "X_trainB_scaled = scalerB.fit_transform(X_trainB_feats)\n",
    "meanB, stdB = evaluate_svm_nested_cv(X_trainB_scaled, y_train_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f74b73-6ce0-4a4b-9244-574f24f10ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
