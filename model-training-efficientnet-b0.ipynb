{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903e7022-8056-47d6-98f3-49022385858b",
   "metadata": {},
   "source": [
    "### Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5293cc2e-8573-444a-8789-00a781e06ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:30:41.735272Z",
     "iopub.status.busy": "2025-10-11T00:30:41.735044Z",
     "iopub.status.idle": "2025-10-11T00:30:49.673538Z",
     "shell.execute_reply": "2025-10-11T00:30:49.672947Z",
     "shell.execute_reply.started": "2025-10-11T00:30:41.735256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, random, numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e98971-b413-4019-9196-c2e39587fd8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:44.431895Z",
     "iopub.status.busy": "2025-10-11T00:31:44.431199Z",
     "iopub.status.idle": "2025-10-11T00:31:44.528689Z",
     "shell.execute_reply": "2025-10-11T00:31:44.528133Z",
     "shell.execute_reply.started": "2025-10-11T00:31:44.431864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e652419-2164-4c00-8e53-18659820b1d7",
   "metadata": {},
   "source": [
    "### Loading the Dataset for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f083d6-5e60-4834-b1bf-f3a45ecab420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:22:39.296291Z",
     "iopub.status.busy": "2025-10-11T05:22:39.296002Z",
     "iopub.status.idle": "2025-10-11T05:22:52.386740Z",
     "shell.execute_reply": "2025-10-11T05:22:52.385998Z",
     "shell.execute_reply.started": "2025-10-11T05:22:39.296269Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (12000, 224, 224, 3) (12000,)\n",
      "Label mapping: {'Boot': 0, 'Sandal': 1, 'Shoe': 2}\n",
      "Prepared tensors: X=(12000, 3, 224, 224), y=(12000,), classes=3\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/kaggle/input/sml-data\"\n",
    "data = np.load(os.path.join(data_dir, \"train_B.npz\"))\n",
    "X, y = data[\"X\"], data[\"y\"]\n",
    "print(\"Loaded dataset:\", X.shape, y.shape)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "print(\"Label mapping:\", dict(zip(encoder.classes_, range(len(encoder.classes_)))))\n",
    "\n",
    "X = X.astype(\"float32\") / 255.0\n",
    "\n",
    "X = np.transpose(X, (0, 3, 1, 2))\n",
    "y = y.astype(\"int64\")\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "print(f\"Prepared tensors: X={X.shape}, y={y.shape}, classes={num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca7bfb-d4bb-41e2-830d-a63d4c575796",
   "metadata": {},
   "source": [
    "### Cross-Validation Split Function\n",
    "Creating stratified kâ€‘fold splits so that each fold maintains similar class proportions, so model evaluation is fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f36bd0-a90a-44fd-811e-e429387796d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:48.679665Z",
     "iopub.status.busy": "2025-10-11T00:31:48.679395Z",
     "iopub.status.idle": "2025-10-11T00:31:48.685275Z",
     "shell.execute_reply": "2025-10-11T00:31:48.684404Z",
     "shell.execute_reply.started": "2025-10-11T00:31:48.679642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_folds(n, k=10, seed=42, y=None):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    unique_classes = np.unique(y)\n",
    "    folds = [[] for _ in range(k)]\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        np.random.shuffle(cls_indices)\n",
    "        cls_splits = np.array_split(cls_indices, k)\n",
    "        for fold_idx, split in enumerate(cls_splits):\n",
    "            folds[fold_idx].extend(split)\n",
    "    \n",
    "    for i in range(k):\n",
    "        np.random.shuffle(folds[i])\n",
    "        folds[i] = np.array(folds[i])\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e3327-8b93-4a70-aa77-c996634b8a7e",
   "metadata": {},
   "source": [
    "### Computing Metrics\n",
    "\n",
    "Manually computing the Confusion Matrix and Evaluation Metrics (Precision, Recall, F1 Score, Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e97b6f6-dea9-4724-9122-2060206b22fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:49.084447Z",
     "iopub.status.busy": "2025-10-11T00:31:49.083770Z",
     "iopub.status.idle": "2025-10-11T00:31:49.088617Z",
     "shell.execute_reply": "2025-10-11T00:31:49.087864Z",
     "shell.execute_reply.started": "2025-10-11T00:31:49.084421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_manual(y_true, y_pred, labels):\n",
    "    n_classes = len(labels)\n",
    "    label_to_idx = {lab: i for i, lab in enumerate(labels)} # mapping each label to an index\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    \n",
    "    for actual, predicted in zip(y_true, y_pred):\n",
    "        i = label_to_idx[actual]\n",
    "        j = label_to_idx[predicted]\n",
    "        cm[i, j] += 1\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aaab744-00b3-497c-9747-d32a7d3e4d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:49.163356Z",
     "iopub.status.busy": "2025-10-11T00:31:49.162857Z",
     "iopub.status.idle": "2025-10-11T00:31:49.167220Z",
     "shell.execute_reply": "2025-10-11T00:31:49.166646Z",
     "shell.execute_reply.started": "2025-10-11T00:31:49.163337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_metrics(cm):\n",
    "    TP = np.diag(cm)\n",
    "    FP = cm.sum(0) - TP\n",
    "    FN = cm.sum(1) - TP\n",
    "    precision = np.mean(TP / (TP + FP + 1e-9))\n",
    "    recall    = np.mean(TP / (TP + FN + 1e-9))\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    acc = TP.sum() / cm.sum()\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed507d11-e57c-446b-9402-3d1104435cfb",
   "metadata": {},
   "source": [
    "### Training & Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc05736-0d14-4d3c-9a4c-6293b7e7bb16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:49.474043Z",
     "iopub.status.busy": "2025-10-11T00:31:49.473472Z",
     "iopub.status.idle": "2025-10-11T00:31:49.480711Z",
     "shell.execute_reply": "2025-10-11T00:31:49.479982Z",
     "shell.execute_reply.started": "2025-10-11T00:31:49.474022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_fold(X_train, y_train, X_val, y_val, model_builder,\n",
    "                   lr=1e-3, epochs=5, batch=64, device=\"cpu\"):\n",
    "\n",
    "    train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "    val_ds   = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "    val_dl   = DataLoader(val_ds, batch_size=batch, shuffle=False)\n",
    "\n",
    "    model = model_builder().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = loss_fn(out, yb)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_dl)\n",
    "        print(f\"For Epoch {ep+1}/{epochs}, The Training loss ={avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in val_dl:\n",
    "            xb = xb.to(device)\n",
    "            probs = torch.softmax(model(xb), 1)\n",
    "            preds.append(torch.argmax(probs, 1).cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return model, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707c8e2-876e-478f-848e-2484aa5bd4aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:49.609428Z",
     "iopub.status.busy": "2025-10-11T00:31:49.609215Z",
     "iopub.status.idle": "2025-10-11T00:31:49.619211Z",
     "shell.execute_reply": "2025-10-11T00:31:49.618587Z",
     "shell.execute_reply.started": "2025-10-11T00:31:49.609411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model_nested_cv(\n",
    "    X, y, model_builder,\n",
    "    candidate_lr=[1e-3, 3e-4, 1e-4],\n",
    "    k_outer=10, k_inner=3, epochs=5,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "\n",
    "    folds = make_folds(len(X), k_outer, seed=42, y=y)\n",
    "    metrics_all = []\n",
    "\n",
    "    for i in range(k_outer):\n",
    "        print(f\"\\n\\n\\n For Outer Fold {i+1}/{k_outer}:\")\n",
    "\n",
    "        test_idx = folds[i]\n",
    "        train_idx = np.concatenate([folds[j] for j in range(k_outer) if j != i])\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test,  y_test  = X[test_idx],  y[test_idx]\n",
    "\n",
    "        print(\"\tFor tuning the Hyperparameter:\")\n",
    "        inner_folds = make_folds(len(X_train), k_inner, seed=42, y=y_train)\n",
    "        mean_accs = []\n",
    "\n",
    "        for lr in candidate_lr:\n",
    "            inner_scores = []\n",
    "            for j in range(k_inner):\n",
    "                val_idx = inner_folds[j]\n",
    "                tr_idx  = np.concatenate([inner_folds[m] for m in range(k_inner) if m != j])\n",
    "\n",
    "                _, y_pred_val = train_one_fold(\n",
    "                    X_train[tr_idx], y_train[tr_idx],\n",
    "                    X_train[val_idx], y_train[val_idx],\n",
    "                    model_builder=model_builder,\n",
    "                    lr=lr, epochs=2, device=device\n",
    "                )\n",
    "\n",
    "                cm = confusion_matrix_manual(y_train[val_idx], y_pred_val, labels=np.unique(y))\n",
    "                acc, prec, rec, f1 = calc_metrics(cm)\n",
    "                inner_scores.append(acc)\n",
    "\n",
    "            mean_accs.append(np.mean(inner_scores))\n",
    "\n",
    "        best_lr = candidate_lr[int(np.argmax(mean_accs))]\n",
    "        print(f\"Best LR = {best_lr:.0e}\")\n",
    "\n",
    "        model, y_pred = train_one_fold(\n",
    "            X_train, y_train, X_test, y_test,\n",
    "            model_builder=model_builder,\n",
    "            lr=best_lr, epochs=epochs, device=device\n",
    "        )\n",
    "\n",
    "        cm = confusion_matrix_manual(y_test, y_pred, labels=np.unique(y))\n",
    "        acc, prec, rec, f1 = calc_metrics(cm)\n",
    "        metrics_all.append([acc, prec, rec, f1])\n",
    "\n",
    "        print(f\"Fold {i+1}: Accuracy Score = {acc:.3f}, Precision = {prec:.3f}, Recall = {rec:.3f}, F1 Score = {f1:.3f}\")\n",
    "\n",
    "    metrics_all = np.array(metrics_all)\n",
    "    mean, std = metrics_all.mean(0), metrics_all.std(0)\n",
    "\n",
    "    print(\"\\n\\n Summary for the Nested CV Training:\")\n",
    "    print(f\"Accuracy Score: {mean[0]:.4f} +/- {std[0]:.4f}\")\n",
    "    print(f\"Precision Score: {mean[1]:.4f} +/- {std[1]:.4f}\")\n",
    "    print(f\"Recall Score: {mean[2]:.4f} +/- {std[2]:.4f}\")\n",
    "    print(f\"F1-score Score: {mean[3]:.4f} +/- {std[3]:.4f}\")\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdf9e1e-6924-4d51-8bad-99c4c5246183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:31:54.611408Z",
     "iopub.status.busy": "2025-10-11T00:31:54.611065Z",
     "iopub.status.idle": "2025-10-11T00:31:54.616124Z",
     "shell.execute_reply": "2025-10-11T00:31:54.615196Z",
     "shell.execute_reply.started": "2025-10-11T00:31:54.611385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_b0(num_classes):\n",
    "    model = models.efficientnet_b0(weights=None)\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.35),\n",
    "        nn.Linear(in_features, num_classes),\n",
    "        nn.BatchNorm1d(num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530e5dc-99b9-4420-8187-3b68078366ce",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaccffd-ab70-42d6-91a9-1343757412fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T15:22:04.297159Z",
     "iopub.status.busy": "2025-10-09T15:22:04.296933Z",
     "iopub.status.idle": "2025-10-09T19:51:03.647536Z",
     "shell.execute_reply": "2025-10-09T19:51:03.646616Z",
     "shell.execute_reply.started": "2025-10-09T15:22:04.297144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Evaluating EfficientNetâ€‘B0 ###\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 1/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.9004\n",
      "For Epoch 2/2, The Training loss =0.5505\n",
      "For Epoch 1/2, The Training loss =0.8289\n",
      "For Epoch 2/2, The Training loss =0.4918\n",
      "For Epoch 1/2, The Training loss =0.7883\n",
      "For Epoch 2/2, The Training loss =0.4794\n",
      "For Epoch 1/2, The Training loss =0.8433\n",
      "For Epoch 2/2, The Training loss =0.5294\n",
      "For Epoch 1/2, The Training loss =0.8911\n",
      "For Epoch 2/2, The Training loss =0.5392\n",
      "For Epoch 1/2, The Training loss =0.9208\n",
      "For Epoch 2/2, The Training loss =0.5239\n",
      "For Epoch 1/2, The Training loss =0.8908\n",
      "For Epoch 2/2, The Training loss =0.5722\n",
      "For Epoch 1/2, The Training loss =0.9296\n",
      "For Epoch 2/2, The Training loss =0.5910\n",
      "For Epoch 1/2, The Training loss =0.9417\n",
      "For Epoch 2/2, The Training loss =0.6393\n",
      "For Epoch 1/2, The Training loss =1.0038\n",
      "For Epoch 2/2, The Training loss =0.6722\n",
      "For Epoch 1/2, The Training loss =0.9805\n",
      "For Epoch 2/2, The Training loss =0.6465\n",
      "For Epoch 1/2, The Training loss =0.9885\n",
      "For Epoch 2/2, The Training loss =0.6698\n",
      "For Epoch 1/2, The Training loss =1.0828\n",
      "For Epoch 2/2, The Training loss =0.8842\n",
      "For Epoch 1/2, The Training loss =1.0462\n",
      "For Epoch 2/2, The Training loss =0.7872\n",
      "For Epoch 1/2, The Training loss =1.0802\n",
      "For Epoch 2/2, The Training loss =0.8476\n",
      "Best LR = 1e-03\n",
      "For Epoch 1/3, The Training loss =0.7809\n",
      "For Epoch 2/3, The Training loss =0.4363\n",
      "For Epoch 3/3, The Training loss =0.3148\n",
      "Fold 1: Accuracy Score = 0.914, Precision = 0.918, Recall = 0.914, F1 Score = 0.916\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 2/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8273\n",
      "For Epoch 2/2, The Training loss =0.5098\n",
      "For Epoch 1/2, The Training loss =0.7708\n",
      "For Epoch 2/2, The Training loss =0.4601\n",
      "For Epoch 1/2, The Training loss =0.7989\n",
      "For Epoch 2/2, The Training loss =0.5011\n",
      "For Epoch 1/2, The Training loss =0.8686\n",
      "For Epoch 2/2, The Training loss =0.5378\n",
      "For Epoch 1/2, The Training loss =0.9445\n",
      "For Epoch 2/2, The Training loss =0.5973\n",
      "For Epoch 1/2, The Training loss =0.8528\n",
      "For Epoch 2/2, The Training loss =0.5058\n",
      "For Epoch 1/2, The Training loss =0.9814\n",
      "For Epoch 2/2, The Training loss =0.6619\n",
      "For Epoch 1/2, The Training loss =0.9009\n",
      "For Epoch 2/2, The Training loss =0.6157\n",
      "For Epoch 1/2, The Training loss =0.9026\n",
      "For Epoch 2/2, The Training loss =0.5710\n",
      "For Epoch 1/2, The Training loss =1.0139\n",
      "For Epoch 2/2, The Training loss =0.6902\n",
      "For Epoch 1/2, The Training loss =0.9973\n",
      "For Epoch 2/2, The Training loss =0.6821\n",
      "For Epoch 1/2, The Training loss =0.9697\n",
      "For Epoch 2/2, The Training loss =0.6467\n",
      "For Epoch 1/2, The Training loss =1.0794\n",
      "For Epoch 2/2, The Training loss =0.8642\n",
      "For Epoch 1/2, The Training loss =1.0770\n",
      "For Epoch 2/2, The Training loss =0.8510\n",
      "For Epoch 1/2, The Training loss =1.0865\n",
      "For Epoch 2/2, The Training loss =0.8912\n",
      "Best LR = 3e-03\n",
      "For Epoch 1/3, The Training loss =0.6987\n",
      "For Epoch 2/3, The Training loss =0.3693\n",
      "For Epoch 3/3, The Training loss =0.2611\n",
      "Fold 2: Accuracy Score = 0.882, Precision = 0.897, Recall = 0.882, F1 Score = 0.889\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 3/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8521\n",
      "For Epoch 2/2, The Training loss =0.5198\n",
      "For Epoch 1/2, The Training loss =0.8594\n",
      "For Epoch 2/2, The Training loss =0.5821\n",
      "For Epoch 1/2, The Training loss =0.7944\n",
      "For Epoch 2/2, The Training loss =0.4680\n",
      "For Epoch 1/2, The Training loss =0.7885\n",
      "For Epoch 2/2, The Training loss =0.4943\n",
      "For Epoch 1/2, The Training loss =0.8635\n",
      "For Epoch 2/2, The Training loss =0.4956\n",
      "For Epoch 1/2, The Training loss =0.8258\n",
      "For Epoch 2/2, The Training loss =0.4844\n",
      "For Epoch 1/2, The Training loss =0.9351\n",
      "For Epoch 2/2, The Training loss =0.5937\n",
      "For Epoch 1/2, The Training loss =0.9082\n",
      "For Epoch 2/2, The Training loss =0.5762\n",
      "For Epoch 1/2, The Training loss =0.9915\n",
      "For Epoch 2/2, The Training loss =0.6432\n",
      "For Epoch 1/2, The Training loss =0.9504\n",
      "For Epoch 2/2, The Training loss =0.6331\n",
      "For Epoch 1/2, The Training loss =0.9781\n",
      "For Epoch 2/2, The Training loss =0.6457\n",
      "For Epoch 1/2, The Training loss =0.9738\n",
      "For Epoch 2/2, The Training loss =0.6487\n",
      "For Epoch 1/2, The Training loss =1.0689\n",
      "For Epoch 2/2, The Training loss =0.8419\n",
      "For Epoch 1/2, The Training loss =1.0769\n",
      "For Epoch 2/2, The Training loss =0.8420\n",
      "For Epoch 1/2, The Training loss =1.1006\n",
      "For Epoch 2/2, The Training loss =0.8957\n",
      "Best LR = 1e-03\n",
      "For Epoch 1/3, The Training loss =0.7727\n",
      "For Epoch 2/3, The Training loss =0.4135\n",
      "For Epoch 3/3, The Training loss =0.3010\n",
      "Fold 3: Accuracy Score = 0.927, Precision = 0.929, Recall = 0.927, F1 Score = 0.928\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 4/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8995\n",
      "For Epoch 2/2, The Training loss =0.5556\n",
      "For Epoch 1/2, The Training loss =0.8342\n",
      "For Epoch 2/2, The Training loss =0.4984\n",
      "For Epoch 1/2, The Training loss =0.8079\n",
      "For Epoch 2/2, The Training loss =0.4581\n",
      "For Epoch 1/2, The Training loss =0.8316\n",
      "For Epoch 2/2, The Training loss =0.5030\n",
      "For Epoch 1/2, The Training loss =0.8245\n",
      "For Epoch 2/2, The Training loss =0.4781\n",
      "For Epoch 1/2, The Training loss =0.8305\n",
      "For Epoch 2/2, The Training loss =0.5088\n",
      "For Epoch 1/2, The Training loss =0.9659\n",
      "For Epoch 2/2, The Training loss =0.6226\n",
      "For Epoch 1/2, The Training loss =0.8903\n",
      "For Epoch 2/2, The Training loss =0.5653\n",
      "For Epoch 1/2, The Training loss =0.8891\n",
      "For Epoch 2/2, The Training loss =0.5660\n",
      "For Epoch 1/2, The Training loss =1.0099\n",
      "For Epoch 2/2, The Training loss =0.6259\n",
      "For Epoch 1/2, The Training loss =1.0310\n",
      "For Epoch 2/2, The Training loss =0.7057\n",
      "For Epoch 1/2, The Training loss =0.9256\n",
      "For Epoch 2/2, The Training loss =0.6285\n",
      "For Epoch 1/2, The Training loss =1.1073\n",
      "For Epoch 2/2, The Training loss =0.9420\n",
      "For Epoch 1/2, The Training loss =1.0748\n",
      "For Epoch 2/2, The Training loss =0.8524\n",
      "For Epoch 1/2, The Training loss =1.1053\n",
      "For Epoch 2/2, The Training loss =0.8482\n",
      "Best LR = 1e-03\n",
      "For Epoch 1/3, The Training loss =0.7274\n",
      "For Epoch 2/3, The Training loss =0.3784\n",
      "For Epoch 3/3, The Training loss =0.2807\n",
      "Fold 4: Accuracy Score = 0.927, Precision = 0.928, Recall = 0.927, F1 Score = 0.927\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 5/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8332\n",
      "For Epoch 2/2, The Training loss =0.5126\n",
      "For Epoch 1/2, The Training loss =0.8408\n",
      "For Epoch 2/2, The Training loss =0.5317\n",
      "For Epoch 1/2, The Training loss =0.8144\n",
      "For Epoch 2/2, The Training loss =0.4824\n",
      "For Epoch 1/2, The Training loss =0.8864\n",
      "For Epoch 2/2, The Training loss =0.5414\n",
      "For Epoch 1/2, The Training loss =0.8853\n",
      "For Epoch 2/2, The Training loss =0.5289\n",
      "For Epoch 1/2, The Training loss =0.8280\n",
      "For Epoch 2/2, The Training loss =0.5015\n",
      "For Epoch 1/2, The Training loss =0.9154\n",
      "For Epoch 2/2, The Training loss =0.5973\n",
      "For Epoch 1/2, The Training loss =0.8567\n",
      "For Epoch 2/2, The Training loss =0.5071\n",
      "For Epoch 1/2, The Training loss =0.9576\n",
      "For Epoch 2/2, The Training loss =0.6206\n",
      "For Epoch 1/2, The Training loss =0.9754\n",
      "For Epoch 2/2, The Training loss =0.6359\n",
      "For Epoch 1/2, The Training loss =0.9503\n",
      "For Epoch 2/2, The Training loss =0.6274\n",
      "For Epoch 1/2, The Training loss =0.9362\n",
      "For Epoch 2/2, The Training loss =0.6226\n",
      "For Epoch 1/2, The Training loss =1.1598\n",
      "For Epoch 2/2, The Training loss =0.9545\n",
      "For Epoch 1/2, The Training loss =1.0462\n",
      "For Epoch 2/2, The Training loss =0.7953\n",
      "For Epoch 1/2, The Training loss =1.0603\n",
      "For Epoch 2/2, The Training loss =0.8241\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.7756\n",
      "For Epoch 2/3, The Training loss =0.4288\n",
      "For Epoch 3/3, The Training loss =0.3218\n",
      "Fold 5: Accuracy Score = 0.892, Precision = 0.897, Recall = 0.892, F1 Score = 0.894\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 6/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8412\n",
      "For Epoch 2/2, The Training loss =0.5058\n",
      "For Epoch 1/2, The Training loss =0.8457\n",
      "For Epoch 2/2, The Training loss =0.5303\n",
      "For Epoch 1/2, The Training loss =0.8360\n",
      "For Epoch 2/2, The Training loss =0.5177\n",
      "For Epoch 1/2, The Training loss =0.8718\n",
      "For Epoch 2/2, The Training loss =0.5354\n",
      "For Epoch 1/2, The Training loss =0.8406\n",
      "For Epoch 2/2, The Training loss =0.5100\n",
      "For Epoch 1/2, The Training loss =0.8548\n",
      "For Epoch 2/2, The Training loss =0.5072\n",
      "For Epoch 1/2, The Training loss =0.9050\n",
      "For Epoch 2/2, The Training loss =0.5767\n",
      "For Epoch 1/2, The Training loss =0.9924\n",
      "For Epoch 2/2, The Training loss =0.6255\n",
      "For Epoch 1/2, The Training loss =0.9157\n",
      "For Epoch 2/2, The Training loss =0.5445\n",
      "For Epoch 1/2, The Training loss =0.9884\n",
      "For Epoch 2/2, The Training loss =0.6756\n",
      "For Epoch 1/2, The Training loss =1.0117\n",
      "For Epoch 2/2, The Training loss =0.6514\n",
      "For Epoch 1/2, The Training loss =1.0290\n",
      "For Epoch 2/2, The Training loss =0.6917\n",
      "For Epoch 1/2, The Training loss =1.0787\n",
      "For Epoch 2/2, The Training loss =0.8379\n",
      "For Epoch 1/2, The Training loss =1.1331\n",
      "For Epoch 2/2, The Training loss =0.8737\n",
      "For Epoch 1/2, The Training loss =1.0975\n",
      "For Epoch 2/2, The Training loss =0.9938\n",
      "Best LR = 1e-03\n",
      "For Epoch 1/3, The Training loss =0.7557\n",
      "For Epoch 2/3, The Training loss =0.4165\n",
      "For Epoch 3/3, The Training loss =0.2986\n",
      "Fold 6: Accuracy Score = 0.908, Precision = 0.915, Recall = 0.908, F1 Score = 0.912\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 7/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8773\n",
      "For Epoch 2/2, The Training loss =0.5357\n",
      "For Epoch 1/2, The Training loss =0.8059\n",
      "For Epoch 2/2, The Training loss =0.4926\n",
      "For Epoch 1/2, The Training loss =0.7811\n",
      "For Epoch 2/2, The Training loss =0.4598\n",
      "For Epoch 1/2, The Training loss =0.9258\n",
      "For Epoch 2/2, The Training loss =0.5484\n",
      "For Epoch 1/2, The Training loss =0.9655\n",
      "For Epoch 2/2, The Training loss =0.5790\n",
      "For Epoch 1/2, The Training loss =0.8394\n",
      "For Epoch 2/2, The Training loss =0.5094\n",
      "For Epoch 1/2, The Training loss =0.9146\n",
      "For Epoch 2/2, The Training loss =0.6088\n",
      "For Epoch 1/2, The Training loss =0.9093\n",
      "For Epoch 2/2, The Training loss =0.5881\n",
      "For Epoch 1/2, The Training loss =0.9022\n",
      "For Epoch 2/2, The Training loss =0.5924\n",
      "For Epoch 1/2, The Training loss =0.9841\n",
      "For Epoch 2/2, The Training loss =0.6757\n",
      "For Epoch 1/2, The Training loss =0.9867\n",
      "For Epoch 2/2, The Training loss =0.6526\n",
      "For Epoch 1/2, The Training loss =0.9994\n",
      "For Epoch 2/2, The Training loss =0.6604\n",
      "For Epoch 1/2, The Training loss =1.0761\n",
      "For Epoch 2/2, The Training loss =0.8728\n",
      "For Epoch 1/2, The Training loss =1.0887\n",
      "For Epoch 2/2, The Training loss =0.8681\n",
      "For Epoch 1/2, The Training loss =1.0601\n",
      "For Epoch 2/2, The Training loss =0.8248\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.7856\n",
      "For Epoch 2/3, The Training loss =0.4704\n",
      "For Epoch 3/3, The Training loss =0.3474\n",
      "Fold 7: Accuracy Score = 0.897, Precision = 0.900, Recall = 0.897, F1 Score = 0.899\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 8/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.8524\n",
      "For Epoch 2/2, The Training loss =0.5389\n",
      "For Epoch 1/2, The Training loss =0.8536\n",
      "For Epoch 2/2, The Training loss =0.5178\n",
      "For Epoch 1/2, The Training loss =0.7450\n",
      "For Epoch 2/2, The Training loss =0.4337\n",
      "For Epoch 1/2, The Training loss =0.8447\n",
      "For Epoch 2/2, The Training loss =0.5345\n",
      "For Epoch 1/2, The Training loss =0.8344\n",
      "For Epoch 2/2, The Training loss =0.4865\n",
      "For Epoch 1/2, The Training loss =0.7923\n",
      "For Epoch 2/2, The Training loss =0.4833\n",
      "For Epoch 1/2, The Training loss =0.9061\n",
      "For Epoch 2/2, The Training loss =0.5677\n",
      "For Epoch 1/2, The Training loss =0.9319\n",
      "For Epoch 2/2, The Training loss =0.5833\n",
      "For Epoch 1/2, The Training loss =0.9178\n",
      "For Epoch 2/2, The Training loss =0.5961\n",
      "For Epoch 1/2, The Training loss =1.0117\n",
      "For Epoch 2/2, The Training loss =0.6740\n",
      "For Epoch 1/2, The Training loss =1.0887\n",
      "For Epoch 2/2, The Training loss =0.7006\n",
      "For Epoch 1/2, The Training loss =0.9594\n",
      "For Epoch 2/2, The Training loss =0.6367\n",
      "For Epoch 1/2, The Training loss =1.0952\n",
      "For Epoch 2/2, The Training loss =0.8132\n",
      "For Epoch 1/2, The Training loss =1.0622\n",
      "For Epoch 2/2, The Training loss =0.8507\n",
      "For Epoch 1/2, The Training loss =1.1220\n",
      "For Epoch 2/2, The Training loss =0.9813\n",
      "Best LR = 1e-03\n",
      "For Epoch 1/3, The Training loss =0.7655\n",
      "For Epoch 2/3, The Training loss =0.4095\n",
      "For Epoch 3/3, The Training loss =0.3009\n",
      "Fold 8: Accuracy Score = 0.923, Precision = 0.924, Recall = 0.923, F1 Score = 0.923\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 9/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.7964\n",
      "For Epoch 2/2, The Training loss =0.4732\n",
      "For Epoch 1/2, The Training loss =0.8861\n",
      "For Epoch 2/2, The Training loss =0.5607\n",
      "For Epoch 1/2, The Training loss =0.8830\n",
      "For Epoch 2/2, The Training loss =0.5642\n",
      "For Epoch 1/2, The Training loss =0.8324\n",
      "For Epoch 2/2, The Training loss =0.5050\n",
      "For Epoch 1/2, The Training loss =0.8253\n",
      "For Epoch 2/2, The Training loss =0.5022\n",
      "For Epoch 1/2, The Training loss =0.9464\n",
      "For Epoch 2/2, The Training loss =0.5775\n",
      "For Epoch 1/2, The Training loss =0.8972\n",
      "For Epoch 2/2, The Training loss =0.5628\n",
      "For Epoch 1/2, The Training loss =0.9237\n",
      "For Epoch 2/2, The Training loss =0.5760\n",
      "For Epoch 1/2, The Training loss =0.9340\n",
      "For Epoch 2/2, The Training loss =0.5844\n",
      "For Epoch 1/2, The Training loss =0.9430\n",
      "For Epoch 2/2, The Training loss =0.6193\n",
      "For Epoch 1/2, The Training loss =0.9472\n",
      "For Epoch 2/2, The Training loss =0.6253\n",
      "For Epoch 1/2, The Training loss =0.9765\n",
      "For Epoch 2/2, The Training loss =0.6494\n",
      "For Epoch 1/2, The Training loss =1.0851\n",
      "For Epoch 2/2, The Training loss =0.8546\n",
      "For Epoch 1/2, The Training loss =1.1223\n",
      "For Epoch 2/2, The Training loss =0.8727\n",
      "For Epoch 1/2, The Training loss =1.0948\n",
      "For Epoch 2/2, The Training loss =0.9140\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.8584\n",
      "For Epoch 2/3, The Training loss =0.4822\n",
      "For Epoch 3/3, The Training loss =0.3547\n",
      "Fold 9: Accuracy Score = 0.928, Precision = 0.928, Recall = 0.928, F1 Score = 0.928\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 10/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.7620\n",
      "For Epoch 2/2, The Training loss =0.4459\n",
      "For Epoch 1/2, The Training loss =0.8958\n",
      "For Epoch 2/2, The Training loss =0.5833\n",
      "For Epoch 1/2, The Training loss =0.7990\n",
      "For Epoch 2/2, The Training loss =0.4940\n",
      "For Epoch 1/2, The Training loss =0.8328\n",
      "For Epoch 2/2, The Training loss =0.4932\n",
      "For Epoch 1/2, The Training loss =0.8815\n",
      "For Epoch 2/2, The Training loss =0.5422\n",
      "For Epoch 1/2, The Training loss =0.8448\n",
      "For Epoch 2/2, The Training loss =0.5228\n",
      "For Epoch 1/2, The Training loss =0.9660\n",
      "For Epoch 2/2, The Training loss =0.6507\n",
      "For Epoch 1/2, The Training loss =0.9372\n",
      "For Epoch 2/2, The Training loss =0.5732\n",
      "For Epoch 1/2, The Training loss =0.8949\n",
      "For Epoch 2/2, The Training loss =0.5661\n",
      "For Epoch 1/2, The Training loss =0.9266\n",
      "For Epoch 2/2, The Training loss =0.6286\n",
      "For Epoch 1/2, The Training loss =1.0272\n",
      "For Epoch 2/2, The Training loss =0.6751\n",
      "For Epoch 1/2, The Training loss =0.8929\n",
      "For Epoch 2/2, The Training loss =0.6174\n",
      "For Epoch 1/2, The Training loss =1.1415\n",
      "For Epoch 2/2, The Training loss =0.8842\n",
      "For Epoch 1/2, The Training loss =1.0716\n",
      "For Epoch 2/2, The Training loss =0.8395\n",
      "For Epoch 1/2, The Training loss =1.0633\n",
      "For Epoch 2/2, The Training loss =0.8477\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.8364\n",
      "For Epoch 2/3, The Training loss =0.4789\n",
      "For Epoch 3/3, The Training loss =0.3465\n",
      "Fold 10: Accuracy Score = 0.877, Precision = 0.884, Recall = 0.877, F1 Score = 0.880\n",
      "\n",
      "\n",
      " Summary for the Nested CV Training:\n",
      "Accuracy Score: 0.9077 +/- 0.0185\n",
      "Precision Score: 0.9119 +/- 0.0153\n",
      "Recall Score: 0.9077 +/- 0.0185\n",
      "F1-score Score: 0.9098 +/- 0.0169\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n### Evaluating EfficientNetâ€‘B0 ###\")\n",
    "eff_mean_B, eff_std_B = evaluate_model_nested_cv(\n",
    "    X, y,\n",
    "    model_builder=lambda: build_efficientnet_b0(num_classes),\n",
    "    candidate_lr= [3e-3, 1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    k_outer=10,\n",
    "    k_inner=3,\n",
    "    epochs=3,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8d9ce-257b-460d-91e0-cbed14a23d04",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e46f8e71-376d-47b1-a0d9-bc01c12ec384",
   "metadata": {},
   "source": [
    "### Saving the Cross Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea614ad2-4ba6-4379-9227-7db40d48c147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T19:51:03.649116Z",
     "iopub.status.busy": "2025-10-09T19:51:03.648768Z",
     "iopub.status.idle": "2025-10-09T19:51:03.655072Z",
     "shell.execute_reply": "2025-10-09T19:51:03.654399Z",
     "shell.execute_reply.started": "2025-10-09T19:51:03.649094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossâ€‘validation results saved to /kaggle/working/cv_results_effb0_trainB.pkl\n"
     ]
    }
   ],
   "source": [
    "cv_results_effb0_B = {\n",
    "    \"mean\": eff_mean_B,\n",
    "    \"std\": eff_std_B,\n",
    "    \"accuracy\": eff_mean_B[0],\n",
    "    \"precision\": eff_mean_B[1],\n",
    "    \"recall\": eff_mean_B[2],\n",
    "    \"f1\": eff_mean_B[3]\n",
    "}\n",
    "\n",
    "save_path = \"/kaggle/working/cv_results_effb0_trainB.pkl\"\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(cv_results_effb0_B, f)\n",
    "\n",
    "print(f\"Crossâ€‘validation results saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e5307-0642-45e4-8edd-6077085fec4a",
   "metadata": {},
   "source": [
    "### Training on the Full Dataset with the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b6f59-06a4-472d-ad96-abb416911633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:23:08.944536Z",
     "iopub.status.busy": "2025-10-11T05:23:08.944275Z",
     "iopub.status.idle": "2025-10-11T05:28:20.965918Z",
     "shell.execute_reply": "2025-10-11T05:28:20.965221Z",
     "shell.execute_reply.started": "2025-10-11T05:23:08.944515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final EfficientNetâ€‘B0 on entire Training Dataset:\n",
      "\n",
      "  Epoch 1/5 â€“ train loss: 0.7406\n",
      "  Epoch 2/5 â€“ train loss: 0.4215\n",
      "  Epoch 3/5 â€“ train loss: 0.3030\n",
      "  Epoch 4/5 â€“ train loss: 0.2363\n",
      "  Epoch 5/5 â€“ train loss: 0.1820\n",
      "Final EfficientNetâ€‘B0 model saved to /kaggle/working/efficientnetb0_final.pth\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(X, y, model_builder, lr=1e-3, epochs=5, batch=64, device=\"cpu\"):\n",
    "    train_ds = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = model_builder().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop across epochs\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = loss_fn(out, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"  Epoch {ep+1}/{epochs} â€“ train loss: {total_loss/len(train_dl):.4f}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"\\nTraining final EfficientNetâ€‘B0 on entire Training Dataset:\\n\")\n",
    "final_model = train_final_model(\n",
    "    X, y,\n",
    "    model_builder=lambda: build_efficientnet_b0(num_classes),\n",
    "    lr=1e-03,\n",
    "    epochs=5,\n",
    "    batch=64,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model_path = \"/kaggle/working/efficientnetb0_final.pth\"\n",
    "torch.save(final_model.state_dict(), model_path)\n",
    "print(f\"Final EfficientNetâ€‘B0 model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249b89c-cf30-4ed9-be5d-0a2b5361ec61",
   "metadata": {},
   "source": [
    "### Testing the Model on the Final Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dbb099-6549-4cf4-b10b-16eca6f9c6ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:29:58.348861Z",
     "iopub.status.busy": "2025-10-11T05:29:58.348603Z",
     "iopub.status.idle": "2025-10-11T05:30:07.496036Z",
     "shell.execute_reply": "2025-10-11T05:30:07.495334Z",
     "shell.execute_reply.started": "2025-10-11T05:29:58.348840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing the Test Data: \n",
      "Test dataset Loaded: (3000, 224, 224, 3) (3000,)\n",
      "Test tensors Ready: (3000, 3, 224, 224)\n",
      "\n",
      "Evaluating final EfficientNetâ€‘B0 on test dataset:\n",
      "\n",
      "Final Results on the Test Dataset (Metrics and the Confusion Matrix): \n",
      "Accuracy : 0.9430\n",
      "Precision: 0.9443\n",
      "Recall   : 0.9430\n",
      "F1â€‘score : 0.9436\n",
      "\n",
      "Confusion Matrix:\n",
      "[[967  14  19]\n",
      " [ 20 898  82]\n",
      " [ 16  20 964]]\n",
      "Classes: ['Boot' 'Sandal' 'Shoe']\n",
      "\n",
      "=== CV vs. Test Comparison ===\n",
      "CV Accuracy : 0.9077 Â± 0.0185\n",
      "Test Accuracy: 0.9430\n",
      "Difference   : 0.0353\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading and preparing the Test Data: \")\n",
    "# Loading the heldâ€‘out test dataset\n",
    "test_data = np.load(os.path.join(data_dir, \"test.npz\"))\n",
    "X_test, y_test = test_data[\"X\"], test_data[\"y\"]\n",
    "print(\"Test dataset Loaded:\", X_test.shape, y_test.shape)\n",
    "\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2))\n",
    "y_test = y_test.astype(\"int64\")\n",
    "print(\"Test tensors Ready:\", X_test.shape)\n",
    "\n",
    "test_ds = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"\\nEvaluating final EfficientNetâ€‘B0 on test dataset:\")\n",
    "model = build_efficientnet_b0(num_classes)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "y_pred_test = []\n",
    "with torch.no_grad():\n",
    "    for xb, _ in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        probs = torch.softmax(model(xb), dim=1)\n",
    "        y_pred_test.append(torch.argmax(probs, 1).cpu().numpy())\n",
    "y_pred_test = np.concatenate(y_pred_test)\n",
    "\n",
    "# calculating the prediction metrics\n",
    "cm_test = confusion_matrix_manual(y_test, y_pred_test, labels=np.unique(y_test))\n",
    "acc_test, prec_test, rec_test, f1_test = calc_metrics(cm_test)\n",
    "\n",
    "print(\"\\nFinal Results on the Test Dataset (Metrics and the Confusion Matrix): \")\n",
    "print(f\"Accuracy : {acc_test:.4f}\")\n",
    "print(f\"Precision: {prec_test:.4f}\")\n",
    "print(f\"Recall   : {rec_test:.4f}\")\n",
    "print(f\"F1â€‘score : {f1_test:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_test)\n",
    "print(\"Classes:\", encoder.classes_)\n",
    "\n",
    "cv_path = \"/kaggle/input/pklfiles/cv_results_effb0_trainB.pkl\"\n",
    "\n",
    "with open(cv_path, \"rb\") as f:\n",
    "    cv_results_effb0 = pickle.load(f)\n",
    "\n",
    "cv_acc_mean  = cv_results_effb0[\"accuracy\"]\n",
    "cv_acc_std   = cv_results_effb0[\"std\"][0]\n",
    "\n",
    "print(\"\\n=== CV vs. Test Comparison ===\")\n",
    "print(f\"CV Accuracy : {cv_acc_mean:.4f} Â± {cv_acc_std:.4f}\")\n",
    "print(f\"Test Accuracy: {acc_test:.4f}\")\n",
    "print(f\"Difference   : {acc_test - cv_acc_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f283da0-8ee2-4a8f-9f0f-35bcaa66af18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:31:36.184905Z",
     "iopub.status.busy": "2025-10-11T05:31:36.184644Z",
     "iopub.status.idle": "2025-10-11T05:31:37.960374Z",
     "shell.execute_reply": "2025-10-11T05:31:37.959652Z",
     "shell.execute_reply.started": "2025-10-11T05:31:36.184884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bootstrapping All Metrics on Test Dataset (Modelâ€¯B) ===\n",
      "  ACC: 0.9432  [0.9343, 0.9510]\n",
      " PREC: 0.9445  [0.9359, 0.9522]\n",
      "  REC: 0.9432  [0.9346, 0.9511]\n",
      "   F1: 0.9438  [0.9351, 0.9516]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Bootstrapping All Metrics on Test Dataset (Modelâ€¯B) ===\")\n",
    "boot_stats_B = bootstrap_metrics(y_test, y_pred_test)\n",
    "\n",
    "for metric, (mean, low, high) in boot_stats_B.items():\n",
    "    print(f\"{metric.upper():>5}: {mean:.4f}  [{low:.4f}, {high:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e143927-b3b6-4acf-8cac-3aeb1a1530a7",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94439679-e2b3-49b2-a974-8a2bc6423e7e",
   "metadata": {
    "trusted": true
   },
   "source": [
    "### Same Application for Model using Train A (Clean Data without Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39af906-791e-4aeb-ac54-60d8b9db91fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:32:05.376704Z",
     "iopub.status.busy": "2025-10-11T00:32:05.375865Z",
     "iopub.status.idle": "2025-10-11T00:32:24.636276Z",
     "shell.execute_reply": "2025-10-11T00:32:24.635586Z",
     "shell.execute_reply.started": "2025-10-11T00:32:05.376673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (12000, 224, 224, 3) (12000,)\n",
      "Label mapping: {'Boot': 0, 'Sandal': 1, 'Shoe': 2}\n",
      "Final tensors: (12000, 3, 224, 224) Classes: 3\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/kaggle/input/sml-data\"\n",
    "data = np.load(os.path.join(data_dir, \"train_A.npz\"))\n",
    "X, y = data[\"X\"], data[\"y\"]\n",
    "print(\"Loaded:\", X.shape, y.shape)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "print(\"Label mapping:\", dict(zip(encoder.classes_,\n",
    "                                 range(len(encoder.classes_)))))\n",
    "\n",
    "X = X.astype(\"float32\") / 255.0\n",
    "\n",
    "X = np.transpose(X, (0,3,1,2))\n",
    "y = y.astype(\"int64\")\n",
    "num_classes = len(np.unique(y))\n",
    "print(\"Final tensors:\", X.shape, \"Classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38cb322c-5e74-42a9-bd61-435d6057b809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T00:32:24.637707Z",
     "iopub.status.busy": "2025-10-11T00:32:24.637476Z",
     "iopub.status.idle": "2025-10-11T04:38:36.955889Z",
     "shell.execute_reply": "2025-10-11T04:38:36.955049Z",
     "shell.execute_reply.started": "2025-10-11T00:32:24.637690Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Evaluating EfficientNetâ€‘B0 ###\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 1/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.5874\n",
      "For Epoch 2/2, The Training loss =0.3059\n",
      "For Epoch 1/2, The Training loss =0.5637\n",
      "For Epoch 2/2, The Training loss =0.2998\n",
      "For Epoch 1/2, The Training loss =0.5653\n",
      "For Epoch 2/2, The Training loss =0.2929\n",
      "For Epoch 1/2, The Training loss =0.6150\n",
      "For Epoch 2/2, The Training loss =0.3359\n",
      "For Epoch 1/2, The Training loss =0.6137\n",
      "For Epoch 2/2, The Training loss =0.3386\n",
      "For Epoch 1/2, The Training loss =0.5901\n",
      "For Epoch 2/2, The Training loss =0.3229\n",
      "For Epoch 1/2, The Training loss =0.6330\n",
      "For Epoch 2/2, The Training loss =0.3547\n",
      "For Epoch 1/2, The Training loss =0.6588\n",
      "For Epoch 2/2, The Training loss =0.3716\n",
      "For Epoch 1/2, The Training loss =0.7089\n",
      "For Epoch 2/2, The Training loss =0.3858\n",
      "For Epoch 1/2, The Training loss =0.7293\n",
      "For Epoch 2/2, The Training loss =0.4127\n",
      "For Epoch 1/2, The Training loss =0.7217\n",
      "For Epoch 2/2, The Training loss =0.4207\n",
      "For Epoch 1/2, The Training loss =0.7695\n",
      "For Epoch 2/2, The Training loss =0.4338\n",
      "For Epoch 1/2, The Training loss =0.9064\n",
      "For Epoch 2/2, The Training loss =0.6109\n",
      "For Epoch 1/2, The Training loss =0.8812\n",
      "For Epoch 2/2, The Training loss =0.5900\n",
      "For Epoch 1/2, The Training loss =0.8884\n",
      "For Epoch 2/2, The Training loss =0.6269\n",
      "Best LR = 3e-04\n",
      "For Epoch 1/3, The Training loss =0.6114\n",
      "For Epoch 2/3, The Training loss =0.3482\n",
      "For Epoch 3/3, The Training loss =0.2728\n",
      "Fold 1: Accuracy Score = 0.958, Precision = 0.959, Recall = 0.958, F1 Score = 0.959\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 2/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.5399\n",
      "For Epoch 2/2, The Training loss =0.2808\n",
      "For Epoch 1/2, The Training loss =0.6085\n",
      "For Epoch 2/2, The Training loss =0.3156\n",
      "For Epoch 1/2, The Training loss =0.6040\n",
      "For Epoch 2/2, The Training loss =0.2931\n",
      "For Epoch 1/2, The Training loss =0.5965\n",
      "For Epoch 2/2, The Training loss =0.3200\n",
      "For Epoch 1/2, The Training loss =0.6291\n",
      "For Epoch 2/2, The Training loss =0.3289\n",
      "For Epoch 1/2, The Training loss =0.5885\n",
      "For Epoch 2/2, The Training loss =0.3107\n",
      "For Epoch 1/2, The Training loss =0.6576\n",
      "For Epoch 2/2, The Training loss =0.3648\n",
      "For Epoch 1/2, The Training loss =0.7452\n",
      "For Epoch 2/2, The Training loss =0.3854\n",
      "For Epoch 1/2, The Training loss =0.6838\n",
      "For Epoch 2/2, The Training loss =0.3713\n",
      "For Epoch 1/2, The Training loss =0.7326\n",
      "For Epoch 2/2, The Training loss =0.4218\n",
      "For Epoch 1/2, The Training loss =0.7461\n",
      "For Epoch 2/2, The Training loss =0.4072\n",
      "For Epoch 1/2, The Training loss =0.7042\n",
      "For Epoch 2/2, The Training loss =0.4096\n",
      "For Epoch 1/2, The Training loss =0.8683\n",
      "For Epoch 2/2, The Training loss =0.5706\n",
      "For Epoch 1/2, The Training loss =0.8577\n",
      "For Epoch 2/2, The Training loss =0.5489\n",
      "For Epoch 1/2, The Training loss =0.9152\n",
      "For Epoch 2/2, The Training loss =0.6745\n",
      "Best LR = 1e-03\n",
      "For Epoch 1/3, The Training loss =0.5500\n",
      "For Epoch 2/3, The Training loss =0.2839\n",
      "For Epoch 3/3, The Training loss =0.2031\n",
      "Fold 2: Accuracy Score = 0.939, Precision = 0.939, Recall = 0.939, F1 Score = 0.939\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 3/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.5512\n",
      "For Epoch 2/2, The Training loss =0.2689\n",
      "For Epoch 1/2, The Training loss =0.5529\n",
      "For Epoch 2/2, The Training loss =0.2762\n",
      "For Epoch 1/2, The Training loss =0.6066\n",
      "For Epoch 2/2, The Training loss =0.3012\n",
      "For Epoch 1/2, The Training loss =0.5771\n",
      "For Epoch 2/2, The Training loss =0.3208\n",
      "For Epoch 1/2, The Training loss =0.6055\n",
      "For Epoch 2/2, The Training loss =0.3328\n",
      "For Epoch 1/2, The Training loss =0.6720\n",
      "For Epoch 2/2, The Training loss =0.3440\n",
      "For Epoch 1/2, The Training loss =0.6815\n",
      "For Epoch 2/2, The Training loss =0.3933\n",
      "For Epoch 1/2, The Training loss =0.6839\n",
      "For Epoch 2/2, The Training loss =0.3825\n",
      "For Epoch 1/2, The Training loss =0.6718\n",
      "For Epoch 2/2, The Training loss =0.3672\n",
      "For Epoch 1/2, The Training loss =0.7188\n",
      "For Epoch 2/2, The Training loss =0.3960\n",
      "For Epoch 1/2, The Training loss =0.7615\n",
      "For Epoch 2/2, The Training loss =0.4361\n",
      "For Epoch 1/2, The Training loss =0.7346\n",
      "For Epoch 2/2, The Training loss =0.4354\n",
      "For Epoch 1/2, The Training loss =0.8808\n",
      "For Epoch 2/2, The Training loss =0.5982\n",
      "For Epoch 1/2, The Training loss =0.8951\n",
      "For Epoch 2/2, The Training loss =0.5420\n",
      "For Epoch 1/2, The Training loss =0.9689\n",
      "For Epoch 2/2, The Training loss =0.6120\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.6250\n",
      "For Epoch 2/3, The Training loss =0.3316\n",
      "For Epoch 3/3, The Training loss =0.2566\n",
      "Fold 3: Accuracy Score = 0.942, Precision = 0.944, Recall = 0.942, F1 Score = 0.943\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 4/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.5844\n",
      "For Epoch 2/2, The Training loss =0.2888\n",
      "For Epoch 1/2, The Training loss =0.5823\n",
      "For Epoch 2/2, The Training loss =0.2665\n",
      "For Epoch 1/2, The Training loss =0.5487\n",
      "For Epoch 2/2, The Training loss =0.2700\n",
      "For Epoch 1/2, The Training loss =0.6013\n",
      "For Epoch 2/2, The Training loss =0.3243\n",
      "For Epoch 1/2, The Training loss =0.6076\n",
      "For Epoch 2/2, The Training loss =0.3297\n",
      "For Epoch 1/2, The Training loss =0.5932\n",
      "For Epoch 2/2, The Training loss =0.3287\n",
      "For Epoch 1/2, The Training loss =0.6683\n",
      "For Epoch 2/2, The Training loss =0.3703\n",
      "For Epoch 1/2, The Training loss =0.6566\n",
      "For Epoch 2/2, The Training loss =0.3570\n",
      "For Epoch 1/2, The Training loss =0.6442\n",
      "For Epoch 2/2, The Training loss =0.3486\n",
      "For Epoch 1/2, The Training loss =0.7266\n",
      "For Epoch 2/2, The Training loss =0.4110\n",
      "For Epoch 1/2, The Training loss =0.7529\n",
      "For Epoch 2/2, The Training loss =0.4101\n",
      "For Epoch 1/2, The Training loss =0.6980\n",
      "For Epoch 2/2, The Training loss =0.3867\n",
      "For Epoch 1/2, The Training loss =0.9730\n",
      "For Epoch 2/2, The Training loss =0.6152\n",
      "For Epoch 1/2, The Training loss =0.8570\n",
      "For Epoch 2/2, The Training loss =0.5620\n",
      "For Epoch 1/2, The Training loss =0.9213\n",
      "For Epoch 2/2, The Training loss =0.6256\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.5746\n",
      "For Epoch 2/3, The Training loss =0.3164\n",
      "For Epoch 3/3, The Training loss =0.2498\n",
      "Fold 4: Accuracy Score = 0.949, Precision = 0.950, Recall = 0.949, F1 Score = 0.949\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 5/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.5996\n",
      "For Epoch 2/2, The Training loss =0.3027\n",
      "For Epoch 1/2, The Training loss =0.5562\n",
      "For Epoch 2/2, The Training loss =0.2796\n",
      "For Epoch 1/2, The Training loss =0.5943\n",
      "For Epoch 2/2, The Training loss =0.2913\n",
      "For Epoch 1/2, The Training loss =0.6173\n",
      "For Epoch 2/2, The Training loss =0.3369\n",
      "For Epoch 1/2, The Training loss =0.5781\n",
      "For Epoch 2/2, The Training loss =0.3227\n",
      "For Epoch 1/2, The Training loss =0.5880\n",
      "For Epoch 2/2, The Training loss =0.3145\n",
      "For Epoch 1/2, The Training loss =0.6690\n",
      "For Epoch 2/2, The Training loss =0.3539\n",
      "For Epoch 1/2, The Training loss =0.6595\n",
      "For Epoch 2/2, The Training loss =0.3636\n",
      "For Epoch 1/2, The Training loss =0.6627\n",
      "For Epoch 2/2, The Training loss =0.3607\n",
      "For Epoch 1/2, The Training loss =0.7299\n",
      "For Epoch 2/2, The Training loss =0.3906\n",
      "For Epoch 1/2, The Training loss =0.7883\n",
      "For Epoch 2/2, The Training loss =0.4518\n",
      "For Epoch 1/2, The Training loss =0.7957\n",
      "For Epoch 2/2, The Training loss =0.4384\n",
      "For Epoch 1/2, The Training loss =0.9240\n",
      "For Epoch 2/2, The Training loss =0.6322\n",
      "For Epoch 1/2, The Training loss =0.8957\n",
      "For Epoch 2/2, The Training loss =0.5967\n",
      "For Epoch 1/2, The Training loss =0.9495\n",
      "For Epoch 2/2, The Training loss =0.6352\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.6305\n",
      "For Epoch 2/3, The Training loss =0.3270\n",
      "For Epoch 3/3, The Training loss =0.2477\n",
      "Fold 5: Accuracy Score = 0.900, Precision = 0.910, Recall = 0.900, F1 Score = 0.905\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 6/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.6084\n",
      "For Epoch 2/2, The Training loss =0.3043\n",
      "For Epoch 1/2, The Training loss =0.5534\n",
      "For Epoch 2/2, The Training loss =0.2804\n",
      "For Epoch 1/2, The Training loss =0.5333\n",
      "For Epoch 2/2, The Training loss =0.2570\n",
      "For Epoch 1/2, The Training loss =0.6382\n",
      "For Epoch 2/2, The Training loss =0.3253\n",
      "For Epoch 1/2, The Training loss =0.6114\n",
      "For Epoch 2/2, The Training loss =0.3240\n",
      "For Epoch 1/2, The Training loss =0.5974\n",
      "For Epoch 2/2, The Training loss =0.3305\n",
      "For Epoch 1/2, The Training loss =0.6291\n",
      "For Epoch 2/2, The Training loss =0.3494\n",
      "For Epoch 1/2, The Training loss =0.6396\n",
      "For Epoch 2/2, The Training loss =0.3499\n",
      "For Epoch 1/2, The Training loss =0.6623\n",
      "For Epoch 2/2, The Training loss =0.3602\n",
      "For Epoch 1/2, The Training loss =0.7410\n",
      "For Epoch 2/2, The Training loss =0.4324\n",
      "For Epoch 1/2, The Training loss =0.7521\n",
      "For Epoch 2/2, The Training loss =0.4179\n",
      "For Epoch 1/2, The Training loss =0.7066\n",
      "For Epoch 2/2, The Training loss =0.3902\n",
      "For Epoch 1/2, The Training loss =0.8992\n",
      "For Epoch 2/2, The Training loss =0.6134\n",
      "For Epoch 1/2, The Training loss =0.8810\n",
      "For Epoch 2/2, The Training loss =0.5956\n",
      "For Epoch 1/2, The Training loss =0.9418\n",
      "For Epoch 2/2, The Training loss =0.6378\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.5840\n",
      "For Epoch 2/3, The Training loss =0.3153\n",
      "For Epoch 3/3, The Training loss =0.2490\n",
      "Fold 6: Accuracy Score = 0.953, Precision = 0.955, Recall = 0.953, F1 Score = 0.954\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 7/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.6032\n",
      "For Epoch 2/2, The Training loss =0.3032\n",
      "For Epoch 1/2, The Training loss =0.5807\n",
      "For Epoch 2/2, The Training loss =0.2733\n",
      "For Epoch 1/2, The Training loss =0.5729\n",
      "For Epoch 2/2, The Training loss =0.2936\n",
      "For Epoch 1/2, The Training loss =0.5979\n",
      "For Epoch 2/2, The Training loss =0.3274\n",
      "For Epoch 1/2, The Training loss =0.6356\n",
      "For Epoch 2/2, The Training loss =0.3327\n",
      "For Epoch 1/2, The Training loss =0.6718\n",
      "For Epoch 2/2, The Training loss =0.3583\n",
      "For Epoch 1/2, The Training loss =0.7118\n",
      "For Epoch 2/2, The Training loss =0.3748\n",
      "For Epoch 1/2, The Training loss =0.6936\n",
      "For Epoch 2/2, The Training loss =0.3805\n",
      "For Epoch 1/2, The Training loss =0.7165\n",
      "For Epoch 2/2, The Training loss =0.3933\n",
      "For Epoch 1/2, The Training loss =0.7086\n",
      "For Epoch 2/2, The Training loss =0.3880\n",
      "For Epoch 1/2, The Training loss =0.7584\n",
      "For Epoch 2/2, The Training loss =0.4036\n",
      "For Epoch 1/2, The Training loss =0.7606\n",
      "For Epoch 2/2, The Training loss =0.4187\n",
      "For Epoch 1/2, The Training loss =0.9030\n",
      "For Epoch 2/2, The Training loss =0.5963\n",
      "For Epoch 1/2, The Training loss =0.9102\n",
      "For Epoch 2/2, The Training loss =0.5622\n",
      "For Epoch 1/2, The Training loss =0.9538\n",
      "For Epoch 2/2, The Training loss =0.6311\n",
      "Best LR = 3e-04\n",
      "For Epoch 1/3, The Training loss =0.6913\n",
      "For Epoch 2/3, The Training loss =0.3464\n",
      "For Epoch 3/3, The Training loss =0.2780\n",
      "Fold 7: Accuracy Score = 0.947, Precision = 0.948, Recall = 0.947, F1 Score = 0.947\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 8/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.6254\n",
      "For Epoch 2/2, The Training loss =0.2893\n",
      "For Epoch 1/2, The Training loss =0.5721\n",
      "For Epoch 2/2, The Training loss =0.2807\n",
      "For Epoch 1/2, The Training loss =0.5887\n",
      "For Epoch 2/2, The Training loss =0.2721\n",
      "For Epoch 1/2, The Training loss =0.6110\n",
      "For Epoch 2/2, The Training loss =0.3210\n",
      "For Epoch 1/2, The Training loss =0.5755\n",
      "For Epoch 2/2, The Training loss =0.3086\n",
      "For Epoch 1/2, The Training loss =0.5916\n",
      "For Epoch 2/2, The Training loss =0.3221\n",
      "For Epoch 1/2, The Training loss =0.6811\n",
      "For Epoch 2/2, The Training loss =0.3578\n",
      "For Epoch 1/2, The Training loss =0.6576\n",
      "For Epoch 2/2, The Training loss =0.3656\n",
      "For Epoch 1/2, The Training loss =0.6952\n",
      "For Epoch 2/2, The Training loss =0.3790\n",
      "For Epoch 1/2, The Training loss =0.7618\n",
      "For Epoch 2/2, The Training loss =0.4070\n",
      "For Epoch 1/2, The Training loss =0.7925\n",
      "For Epoch 2/2, The Training loss =0.3998\n",
      "For Epoch 1/2, The Training loss =0.7763\n",
      "For Epoch 2/2, The Training loss =0.4237\n",
      "For Epoch 1/2, The Training loss =0.9074\n",
      "For Epoch 2/2, The Training loss =0.5938\n",
      "For Epoch 1/2, The Training loss =0.9473\n",
      "For Epoch 2/2, The Training loss =0.6078\n",
      "For Epoch 1/2, The Training loss =0.9052\n",
      "For Epoch 2/2, The Training loss =0.6056\n",
      "Best LR = 3e-04\n",
      "For Epoch 1/3, The Training loss =0.5987\n",
      "For Epoch 2/3, The Training loss =0.3288\n",
      "For Epoch 3/3, The Training loss =0.2640\n",
      "Fold 8: Accuracy Score = 0.898, Precision = 0.913, Recall = 0.898, F1 Score = 0.906\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 9/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.5805\n",
      "For Epoch 2/2, The Training loss =0.2989\n",
      "For Epoch 1/2, The Training loss =0.5316\n",
      "For Epoch 2/2, The Training loss =0.2838\n",
      "For Epoch 1/2, The Training loss =0.6226\n",
      "For Epoch 2/2, The Training loss =0.3086\n",
      "For Epoch 1/2, The Training loss =0.5995\n",
      "For Epoch 2/2, The Training loss =0.3146\n",
      "For Epoch 1/2, The Training loss =0.5990\n",
      "For Epoch 2/2, The Training loss =0.3151\n",
      "For Epoch 1/2, The Training loss =0.6000\n",
      "For Epoch 2/2, The Training loss =0.3403\n",
      "For Epoch 1/2, The Training loss =0.6478\n",
      "For Epoch 2/2, The Training loss =0.3539\n",
      "For Epoch 1/2, The Training loss =0.6703\n",
      "For Epoch 2/2, The Training loss =0.3703\n",
      "For Epoch 1/2, The Training loss =0.6555\n",
      "For Epoch 2/2, The Training loss =0.3735\n",
      "For Epoch 1/2, The Training loss =0.7222\n",
      "For Epoch 2/2, The Training loss =0.4079\n",
      "For Epoch 1/2, The Training loss =0.7710\n",
      "For Epoch 2/2, The Training loss =0.4497\n",
      "For Epoch 1/2, The Training loss =0.7614\n",
      "For Epoch 2/2, The Training loss =0.4258\n",
      "For Epoch 1/2, The Training loss =0.9313\n",
      "For Epoch 2/2, The Training loss =0.6074\n",
      "For Epoch 1/2, The Training loss =0.9327\n",
      "For Epoch 2/2, The Training loss =0.6170\n",
      "For Epoch 1/2, The Training loss =0.8710\n",
      "For Epoch 2/2, The Training loss =0.5466\n",
      "Best LR = 3e-03\n",
      "For Epoch 1/3, The Training loss =0.4798\n",
      "For Epoch 2/3, The Training loss =0.2225\n",
      "For Epoch 3/3, The Training loss =0.1571\n",
      "Fold 9: Accuracy Score = 0.916, Precision = 0.921, Recall = 0.916, F1 Score = 0.918\n",
      "\n",
      "\n",
      "\n",
      " For Outer Fold 10/10:\n",
      "\tFor tuning the Hyperparameter:\n",
      "For Epoch 1/2, The Training loss =0.6052\n",
      "For Epoch 2/2, The Training loss =0.2987\n",
      "For Epoch 1/2, The Training loss =0.5774\n",
      "For Epoch 2/2, The Training loss =0.2851\n",
      "For Epoch 1/2, The Training loss =0.5573\n",
      "For Epoch 2/2, The Training loss =0.3248\n",
      "For Epoch 1/2, The Training loss =0.6071\n",
      "For Epoch 2/2, The Training loss =0.3303\n",
      "For Epoch 1/2, The Training loss =0.6365\n",
      "For Epoch 2/2, The Training loss =0.3512\n",
      "For Epoch 1/2, The Training loss =0.6150\n",
      "For Epoch 2/2, The Training loss =0.3321\n",
      "For Epoch 1/2, The Training loss =0.6294\n",
      "For Epoch 2/2, The Training loss =0.3460\n",
      "For Epoch 1/2, The Training loss =0.7056\n",
      "For Epoch 2/2, The Training loss =0.3808\n",
      "For Epoch 1/2, The Training loss =0.6726\n",
      "For Epoch 2/2, The Training loss =0.3780\n",
      "For Epoch 1/2, The Training loss =0.7078\n",
      "For Epoch 2/2, The Training loss =0.3888\n",
      "For Epoch 1/2, The Training loss =0.7139\n",
      "For Epoch 2/2, The Training loss =0.3918\n",
      "For Epoch 1/2, The Training loss =0.7775\n",
      "For Epoch 2/2, The Training loss =0.4055\n",
      "For Epoch 1/2, The Training loss =0.9042\n",
      "For Epoch 2/2, The Training loss =0.6039\n",
      "For Epoch 1/2, The Training loss =0.8845\n",
      "For Epoch 2/2, The Training loss =0.5781\n",
      "For Epoch 1/2, The Training loss =0.9369\n",
      "For Epoch 2/2, The Training loss =0.5988\n",
      "Best LR = 5e-04\n",
      "For Epoch 1/3, The Training loss =0.5744\n",
      "For Epoch 2/3, The Training loss =0.3136\n",
      "For Epoch 3/3, The Training loss =0.2370\n",
      "Fold 10: Accuracy Score = 0.957, Precision = 0.958, Recall = 0.957, F1 Score = 0.957\n",
      "\n",
      "\n",
      " Summary for the Nested CV Training:\n",
      "Accuracy Score: 0.9359 +/- 0.0216\n",
      "Precision Score: 0.9397 +/- 0.0175\n",
      "Recall Score: 0.9359 +/- 0.0216\n",
      "F1-score Score: 0.9378 +/- 0.0196\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n### Evaluating EfficientNetâ€‘B0 ###\")\n",
    "eff_mean_A, eff_std_A = evaluate_model_nested_cv(\n",
    "    X, y,\n",
    "    model_builder=lambda: build_efficientnet_b0(num_classes),\n",
    "    candidate_lr= [3e-3, 1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    k_outer=10,\n",
    "    k_inner=3,\n",
    "    epochs=3,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336a52d-4c97-4962-966e-2f65dd35baba",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d3162-9658-4036-8a29-e6aac5899a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T04:47:08.308382Z",
     "iopub.status.busy": "2025-10-11T04:47:08.308115Z",
     "iopub.status.idle": "2025-10-11T04:52:18.236044Z",
     "shell.execute_reply": "2025-10-11T04:52:18.235105Z",
     "shell.execute_reply.started": "2025-10-11T04:47:08.308363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final EfficientNetâ€‘B0 on entire Training Dataset:\n",
      "\n",
      "  Epoch 1/5 â€“ train loss: 0.5682\n",
      "  Epoch 2/5 â€“ train loss: 0.2932\n",
      "  Epoch 3/5 â€“ train loss: 0.2320\n",
      "  Epoch 4/5 â€“ train loss: 0.1955\n",
      "  Epoch 5/5 â€“ train loss: 0.1623\n",
      "Final EfficientNetâ€‘B0 model saved to /kaggle/working/efficientnetb0_final_dataA.pth\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(X, y, model_builder, lr=1e-3, epochs=5, batch=64, device=\"cpu\"):\n",
    "    train_ds = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = model_builder().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = loss_fn(out, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"  Epoch {ep+1}/{epochs} â€“ train loss: {total_loss/len(train_dl):.4f}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"\\nTraining final EfficientNetâ€‘B0 on entire Training Dataset:\\n\")\n",
    "final_model_A = train_final_model(\n",
    "    X, y,\n",
    "    model_builder=lambda: build_efficientnet_b0(num_classes),\n",
    "    lr=5e-04,        # LR chosen after performing cv\n",
    "    epochs=5,\n",
    "    batch=64,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model_path = \"/kaggle/working/efficientnetb0_final_dataA.pth\"\n",
    "torch.save(final_model_A.state_dict(), model_path)\n",
    "print(f\"Final EfficientNetâ€‘B0 model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49411cb1-0bac-48ff-948c-e1e6df572ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:06:30.943598Z",
     "iopub.status.busy": "2025-10-11T05:06:30.943358Z",
     "iopub.status.idle": "2025-10-11T05:06:30.949500Z",
     "shell.execute_reply": "2025-10-11T05:06:30.948873Z",
     "shell.execute_reply.started": "2025-10-11T05:06:30.943581Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CV results to /kaggle/working/cv_results_effb0_trainA.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "cv_results_effb0 = {\n",
    "    \"accuracy\": eff_mean_A[0],\n",
    "    \"precision\": eff_mean_A[1],\n",
    "    \"recall\": eff_mean_A[2],\n",
    "    \"f1\": eff_mean_A[3],\n",
    "    \"std\": eff_std_A\n",
    "}\n",
    "\n",
    "save_path = \"/kaggle/working/cv_results_effb0_trainA.pkl\"\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(cv_results_effb0, f)\n",
    "print(\"Saved CV results to\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafa8b0-d88a-4bca-a928-c2683b2b4ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:32:40.562806Z",
     "iopub.status.busy": "2025-10-11T05:32:40.562572Z",
     "iopub.status.idle": "2025-10-11T05:32:58.033149Z",
     "shell.execute_reply": "2025-10-11T05:32:58.032375Z",
     "shell.execute_reply.started": "2025-10-11T05:32:40.562790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and preparing the Test Data (Dataâ€¯A):\n",
      "Test dataset Loaded: (3000, 224, 224, 3) (3000,)\n",
      "Reâ€‘created encoder. Classes: ['Boot' 'Sandal' 'Shoe']\n",
      "Test tensors Ready: (3000, 3, 224, 224)\n",
      "\n",
      "Evaluating final EfficientNetâ€‘B0 (Dataâ€¯A) on test dataset:\n",
      "\n",
      "=== Final Results on Test Dataset (Modelâ€¯A) ===\n",
      "Accuracy : 0.7250\n",
      "Precision: 0.7288\n",
      "Recall   : 0.7250\n",
      "F1â€‘score : 0.7269\n",
      "\n",
      "Confusion Matrix:\n",
      " [[689 174 137]\n",
      " [109 684 207]\n",
      " [ 74 124 802]]\n",
      "Classes: ['Boot' 'Sandal' 'Shoe']\n",
      "\n",
      "CV result keys: dict_keys(['accuracy', 'precision', 'recall', 'f1', 'std'])\n",
      "\n",
      "=== CV vs. Test Comparison (Dataâ€¯A) ===\n",
      "CV Accuracy : 0.9359 Â± 0.0216\n",
      "Test Accuracy: 0.7250\n",
      "Difference   : -0.2109\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading and preparing the Test Data (Dataâ€¯A):\")\n",
    "\n",
    "data_dir = \"/kaggle/input/sml-data\"\n",
    "test_data = np.load(os.path.join(data_dir, \"test.npz\"))\n",
    "X_test, y_test = test_data[\"X\"], test_data[\"y\"]\n",
    "print(\"Test dataset Loaded:\", X_test.shape, y_test.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_data = np.load(os.path.join(data_dir, \"train_A.npz\"))\n",
    "_, y_trainA = train_data[\"X\"], train_data[\"y\"]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_trainA)\n",
    "print(\"Reâ€‘created encoder. Classes:\", encoder.classes_)\n",
    "\n",
    "y_test = encoder.transform(y_test)\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2))\n",
    "y_test = y_test.astype(\"int64\")\n",
    "print(\"Test tensors Ready:\", X_test.shape)\n",
    "\n",
    "test_ds = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"\\nEvaluating final EfficientNetâ€‘B0 (Dataâ€¯A) on test dataset:\")\n",
    "model_path = \"/kaggle/working/efficientnetb0_final_dataA.pth\"\n",
    "model = build_efficientnet_b0(num_classes=len(encoder.classes_))\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "y_pred_test = []\n",
    "with torch.no_grad():\n",
    "    for xb, _ in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        y_pred_test.append(torch.argmax(model(xb), dim=1).cpu().numpy())\n",
    "y_pred_test = np.concatenate(y_pred_test)\n",
    "\n",
    "cm_test = confusion_matrix_manual(y_test, y_pred_test, labels=np.unique(y_test))\n",
    "acc_test, prec_test, rec_test, f1_test = calc_metrics(cm_test)\n",
    "\n",
    "print(\"\\n=== Final Results on Test Dataset (Modelâ€¯A) ===\")\n",
    "print(f\"Accuracy : {acc_test:.4f}\")\n",
    "print(f\"Precision: {prec_test:.4f}\")\n",
    "print(f\"Recall   : {rec_test:.4f}\")\n",
    "print(f\"F1â€‘score : {f1_test:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", cm_test)\n",
    "print(\"Classes:\", encoder.classes_)\n",
    "\n",
    "cv_path = \"/kaggle/working/cv_results_effb0_trainA.pkl\"\n",
    "with open(cv_path, \"rb\") as f:\n",
    "    cv_results_effb0 = pickle.load(f)\n",
    "\n",
    "print(\"\\nCV result keys:\", cv_results_effb0.keys())\n",
    "\n",
    "cv_acc_mean = cv_results_effb0[\"accuracy\"]\n",
    "cv_acc_std  = cv_results_effb0[\"std\"][0]\n",
    "\n",
    "print(\"\\n=== CV vs. Test Comparison (Dataâ€¯A) ===\")\n",
    "print(f\"CV Accuracy : {cv_acc_mean:.4f} Â± {cv_acc_std:.4f}\")\n",
    "print(f\"Test Accuracy: {acc_test:.4f}\")\n",
    "print(f\"Difference   : {acc_test - cv_acc_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0482e1c-3869-4cee-bfce-594f7f1c6211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:10:42.917792Z",
     "iopub.status.busy": "2025-10-11T05:10:42.917109Z",
     "iopub.status.idle": "2025-10-11T05:10:42.923931Z",
     "shell.execute_reply": "2025-10-11T05:10:42.923368Z",
     "shell.execute_reply.started": "2025-10-11T05:10:42.917755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_metrics(y_true, y_pred, n_bootstrap=1000, confidence=0.95):\n",
    "    n_samples = len(y_true)\n",
    "    results = {\"acc\": [], \"prec\": [], \"rec\": [], \"f1\": []}\n",
    "    labels = np.unique(y_true)\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        y_t, y_p = y_true[idx], y_pred[idx]\n",
    "        cm = confusion_matrix_manual(y_t, y_p, labels=labels)\n",
    "        acc, prec, rec, f1 = calc_metrics(cm)\n",
    "        results[\"acc\"].append(acc)\n",
    "        results[\"prec\"].append(prec)\n",
    "        results[\"rec\"].append(rec)\n",
    "        results[\"f1\"].append(f1)\n",
    "\n",
    "    alpha = (1 - confidence) / 2\n",
    "    stats = {}\n",
    "    for k, v in results.items():\n",
    "        v = np.array(v)\n",
    "        stats[k] = (\n",
    "            np.mean(v),\n",
    "            np.percentile(v, 100 * alpha),\n",
    "            np.percentile(v, 100 * (1 - alpha)),\n",
    "        )\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1430be8-26b1-44d5-8264-bf55dc56d643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:33:11.856518Z",
     "iopub.status.busy": "2025-10-11T05:33:11.856252Z",
     "iopub.status.idle": "2025-10-11T05:33:13.596054Z",
     "shell.execute_reply": "2025-10-11T05:33:13.595331Z",
     "shell.execute_reply.started": "2025-10-11T05:33:11.856497Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bootstrapping All Metrics (Model Train_A) ===\n",
      "  ACC: 0.7250  [0.7080, 0.7410]\n",
      " PREC: 0.7289  [0.7122, 0.7452]\n",
      "  REC: 0.7250  [0.7084, 0.7410]\n",
      "   F1: 0.7269  [0.7104, 0.7431]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Bootstrapping All Metrics (Model Train_A) ===\")\n",
    "boot_stats_A = bootstrap_metrics(y_test, y_pred_test)\n",
    "\n",
    "for metric, (mean, lower, upper) in boot_stats_A.items():\n",
    "    print(f\"{metric.upper():>5}: {mean:.4f}  [{lower:.4f}, {upper:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af38795-97bf-4960-8c5a-92b97a661edd",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14f9ecfa-9d08-4b0a-9ba0-da5612c439c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T05:33:18.022133Z",
     "iopub.status.busy": "2025-10-11T05:33:18.021468Z",
     "iopub.status.idle": "2025-10-11T05:33:18.027102Z",
     "shell.execute_reply": "2025-10-11T05:33:18.026321Z",
     "shell.execute_reply.started": "2025-10-11T05:33:18.022101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison: Modelâ€¯A vsâ€¯Modelâ€¯B (95â€¯%â€¯CI) ===\n",
      "  ACC:\n",
      "  Modelâ€¯A: 0.7250  [0.7080, 0.7410]\n",
      "  Modelâ€¯B: 0.9432  [0.9343, 0.9510]\n",
      "\n",
      " PREC:\n",
      "  Modelâ€¯A: 0.7289  [0.7122, 0.7452]\n",
      "  Modelâ€¯B: 0.9445  [0.9359, 0.9522]\n",
      "\n",
      "  REC:\n",
      "  Modelâ€¯A: 0.7250  [0.7084, 0.7410]\n",
      "  Modelâ€¯B: 0.9432  [0.9346, 0.9511]\n",
      "\n",
      "   F1:\n",
      "  Modelâ€¯A: 0.7269  [0.7104, 0.7431]\n",
      "  Modelâ€¯B: 0.9438  [0.9351, 0.9516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Comparison: Modelâ€¯A vsâ€¯Modelâ€¯B (95â€¯%â€¯CI) ===\")\n",
    "for metric in boot_stats_A.keys():\n",
    "    meanA, lowA, upA = boot_stats_A[metric]\n",
    "    meanB, lowB, upB = boot_stats_B[metric]\n",
    "    print(f\"{metric.upper():>5}:\")\n",
    "    print(f\"  Modelâ€¯A: {meanA:.4f}  [{lowA:.4f}, {upA:.4f}]\")\n",
    "    print(f\"  Modelâ€¯B: {meanB:.4f}  [{lowB:.4f}, {upB:.4f}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e77b2-9bd7-40b6-851a-f0ebefe66253",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8415973,
     "sourceId": 13279737,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8442792,
     "sourceId": 13318157,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8442916,
     "sourceId": 13318313,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8450916,
     "sourceId": 13329606,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
